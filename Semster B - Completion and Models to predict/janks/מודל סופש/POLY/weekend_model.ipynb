{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt  \n",
    "import plotly.graph_objects as go\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "import sys\n",
    "sys.path.append(\"../../utils\")\n",
    "import utils\n",
    "import os\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../../../site_info_ver_3.2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_excel(\"../../../POLY_RESULTS.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True,inplace=True)\n",
    "df = df.dropna(axis = 0)\n",
    "dummies = pd.get_dummies(df, 'Site_Name')\n",
    "dummies.drop(['Model_number','Date'] , axis = 1, inplace = True)\n",
    "dummies = dummies.astype({'Total':np.float64,'Israelis_Count':np.float64, 'Tourists_Count':np.float64})\n",
    "dummies.isna().any().sum()\n",
    "dummies = dummies.loc[dummies.is_weekend == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_res = pd.read_excel(\"./poly.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weekend model : general , corr>=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['Total' , 'Israelis_Count', 'Tourists_Count' ]\n",
    "ys = [dummies.Total , dummies.Israelis_Count , dummies.Tourists_Count]\n",
    "\n",
    "\n",
    "index = 0\n",
    "for target in targets:\n",
    "    #print(target+\"\\n\")\n",
    "    f = open(\"./\"+target+\"_general_weekend.txt\" , \"w\")\n",
    "    for i in range(1,5):\n",
    "        to_drop = [x for x in targets if x != target]\n",
    "        X = dummies.drop(to_drop , axis=1)\n",
    "        corr_df = X.corr()\n",
    "        correlated = corr_df[targets[index]].loc[(abs(corr_df[targets[index]]) >= 0.10)]\n",
    "        \n",
    "        correlated = correlated.drop([targets[index]]).index.tolist()\n",
    "        if len(correlated) == 0:\n",
    "            train_df = None\n",
    "            test_df = None\n",
    "            continue\n",
    "        #targets = [model.Total , model.Israelis_Count , model.Tourists_Count]\n",
    "        #targets_vals = ['Israelis_Count','Tourists_Count','Total']\n",
    "        \n",
    "        #if len(X) == 0: return None , None\n",
    "        X = X[correlated]\n",
    "        if len(X) == 0: \n",
    "            train_df = None\n",
    "            test_df = None\n",
    "            continue\n",
    "        \n",
    "        y = ys[index]\n",
    "        #print(X)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7254)\n",
    "        train_df = pd.merge(left=X_train, right=y_train, left_index=True, right_index=True)\n",
    "        test_df = pd.merge(left=X_test, right=y_test, left_index=True, right_index=True)\n",
    "        x_train_scaler = MinMaxScaler()\n",
    "        x_test_scaler = MinMaxScaler()\n",
    "        # y_train_scaler = MinMaxScaler()\n",
    "        # y_test_scaler = MinMaxScaler()\n",
    "        X_train_scaled = x_train_scaler.fit_transform(X_train)\n",
    "        X_test_scaled = x_test_scaler.fit_transform(X_test)\n",
    "        # y_train_scaled = y_train_scaler.fit_transform(pd.DataFrame(y_train))\n",
    "        # y_test_scaled = y_test_scaler.fit_transform(pd.DataFrame(y_test))\n",
    "        y_train_scaled = np.log(y_train + 0.01)\n",
    "        y_test_scaled = np.log(y_test + 0.01)\n",
    "        poly = PolynomialFeatures(degree=i)\n",
    "        \n",
    "        #fit the x variable to fit a 2rd degree polynomial value\n",
    "        X_poly = poly.fit_transform(X_train_scaled)\n",
    "        poly.fit(X_poly, y_train_scaled)\n",
    "        pol_lin_reg = LinearRegression()\n",
    "        \n",
    "        pol_lin_reg.fit(X_poly, y_train_scaled)\n",
    "        \n",
    "        #predict the training data\n",
    "        y_train_pred_scaled = pol_lin_reg.predict(poly.fit_transform(X_train_scaled))\n",
    "        #y_train_pred = y_train_scaler.inverse_transform(y_train_pred_scaled)\n",
    "        y_train_pred = np.exp(y_train_pred_scaled)\n",
    "        #create a pandas series of the results\n",
    "        y_train_pred = round(pd.Series(y_train_pred, index=y_train.index, name='predicted_entries_train'),ndigits=2)\n",
    "        \n",
    "        #Add the results to the DF\n",
    "        train_df = pd.merge(left=train_df, right=y_train_pred , left_index=True, right_index=True)\n",
    "        #train_df.head()\n",
    "        y_test_pred_scaled = pol_lin_reg.predict(poly.fit_transform(X_test_scaled))\n",
    "        y_test_pred = np.exp(y_test_pred_scaled)\n",
    "        #y_test_pred = y_test_scaler.inverse_transform(y_test_pred_scaled)\n",
    "        #create a pandas series of the results\n",
    "        y_test_pred = round(pd.Series(y_test_pred, index=y_test.index, name='predicted_entries_test'),ndigits=2)\n",
    "        #Add the results to the DF\n",
    "        test_df = pd.merge(left=test_df, right=y_test_pred , left_index=True, right_index=True)\n",
    "        if train_df is None and test_df is None : continue\n",
    "        train_mse = metrics.mean_squared_error(train_df[targets[index]], train_df.predicted_entries_train)\n",
    "        train_rmse = np.sqrt(metrics.mean_squared_error(train_df[targets[index]], train_df.predicted_entries_train))\n",
    "        train_mae = metrics.mean_absolute_error(train_df[targets[index]], train_df.predicted_entries_train)\n",
    "        train_std = np.std(train_df.predicted_entries_train)\n",
    "        r2_train = r2_score(train_df[targets[index]], train_df.predicted_entries_train)\n",
    "        f.write(\"Degrees: \"+str(i)+\",Target: \"+target+\"\\n\")\n",
    "        f.write(\"------ TRAIN DATA ------\\n\")\n",
    "        f.write(\"MSE : \"+str(train_mse)+\", RMSE: \"+str(train_rmse)+\", MAE : \"+str(train_mae)+\"\\n\")\n",
    "        f.write(\"R2 TRAIN \"+ str(r2_train)+\"\\n\")\n",
    "        f.write(\"TRAIN STD \"+str(train_std)+\"\\n\")\n",
    "        try:\n",
    "            test_mse = metrics.mean_squared_error(test_df[targets[index]], test_df.predicted_entries_test)\n",
    "        except: pass\n",
    "        try:\n",
    "            test_rmse = np.sqrt(metrics.mean_squared_error(test_df[targets[index]], test_df.predicted_entries_test))\n",
    "        except: pass\n",
    "        try:\n",
    "            test_mae = metrics.mean_absolute_error(test_df[targets[index]], test_df.predicted_entries_test)\n",
    "        except: pass\n",
    "        try:\n",
    "            r2_test = r2_score(test_df[targets[index]], test_df.predicted_entries_test)\n",
    "        except: pass\n",
    "        \n",
    "        test_std = np.std(test_df.predicted_entries_test)\n",
    "        f.write(\"------ TEST DATA ------\\n\")\n",
    "        f.write(\"MSE : \"+str(test_mse)+\", RMSE: \"+str(test_rmse)+\", MAE : \"+str(test_mae)+\"\\n\")\n",
    "        f.write(\"R2 TEST \"+ str(r2_test)+\"\\n\")\n",
    "        f.write(\"TEST STD \"+str(test_std)+\"\\n\")\n",
    "        f.write(\"--------------------------------\\n\")\n",
    "        \n",
    "        coeff = pol_lin_reg.coef_\n",
    "        #print(coeff)\n",
    "        #intercept = pol_lin_reg.intercept_\n",
    "        equation =\"\"+ str(pol_lin_reg.intercept_)\n",
    "        for idx in range(len(X.columns)):\n",
    "            equation += \" + \"+str(round(coeff[idx],4))+\" * \"+str(X.columns[idx])\n",
    "        new_row = {'Descripton':'general weekend model , corr >= 0.10 ,','Degree':str(i),'Target':target,'Model_type':'POLY',\n",
    "        'MAE_Training':train_mae,'MSE_Training':train_mse,\n",
    "    'RMSE_Training': train_rmse,'R2_Training': r2_train,\n",
    "    'MAE_Test':test_mae,'MSE_Test':test_mse,'RMSE_Test': test_rmse,'R2_Test': r2_test,'TRAIN_STD':train_std,\n",
    "    'TEST_STD':test_std , 'EQUATION' : str(equation),'TEST_SIZE' : len(test_df),'TRAIN_SIZE':len(train_df)}\n",
    "    \n",
    "        poly_res = poly_res.append(new_row,ignore_index=True)\n",
    "        #return train_df,test_df\n",
    "    index += 1\n",
    "    f.close()\n",
    "poly_res.to_excel(\"./poly.xlsx\",index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weekend model : general , uni test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['Total' , 'Israelis_Count', 'Tourists_Count' ]\n",
    "ys = [dummies.Total , dummies.Israelis_Count , dummies.Tourists_Count]\n",
    "\n",
    "\n",
    "index = 0\n",
    "for target in targets:\n",
    "    #print(target+\"\\n\")\n",
    "    f = open(\"./\"+target+\"_weekend_UNI.txt\" , \"w\")\n",
    "    to_drop = [x for x in targets if x != target]\n",
    "    #print(to_drop)\n",
    "    for i in range(1,5):\n",
    "        \n",
    "        X = dummies.drop(to_drop , axis=1)\n",
    "        \n",
    "        y = ys[index]\n",
    "        chi_selector = SelectKBest(f_regression, k=10)\n",
    "        chi_selector.fit(X, y)\n",
    "        chi_support = chi_selector.get_support()\n",
    "        chi_feature = X.loc[:,chi_support].columns.to_list()\n",
    "        if target in chi_feature : chi_feature.remove(target)\n",
    "        X = X[chi_feature]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7254)\n",
    "        train_df = pd.merge(left=X_train, right=y_train, left_index=True, right_index=True)\n",
    "        test_df = pd.merge(left=X_test, right=y_test, left_index=True, right_index=True)\n",
    "        x_train_scaler = MinMaxScaler()\n",
    "        x_test_scaler = MinMaxScaler()\n",
    "        # y_train_scaler = MinMaxScaler()\n",
    "        # y_test_scaler = MinMaxScaler()\n",
    "        X_train_scaled = x_train_scaler.fit_transform(X_train)\n",
    "        X_test_scaled = x_test_scaler.fit_transform(X_test)\n",
    "        # y_train_scaled = y_train_scaler.fit_transform(pd.DataFrame(y_train))\n",
    "        # y_test_scaled = y_test_scaler.fit_transform(pd.DataFrame(y_test))\n",
    "        y_train_scaled = np.log(y_train + 0.01)\n",
    "        y_test_scaled = np.log(y_test + 0.01)\n",
    "        poly = PolynomialFeatures(degree=i)\n",
    "        \n",
    "        #fit the x variable to fit a 2rd degree polynomial value\n",
    "        X_poly = poly.fit_transform(X_train_scaled)\n",
    "        poly.fit(X_poly, y_train_scaled)\n",
    "        pol_lin_reg = LinearRegression()\n",
    "        \n",
    "        pol_lin_reg.fit(X_poly, y_train_scaled)\n",
    "        \n",
    "        #predict the training data\n",
    "        y_train_pred_scaled = pol_lin_reg.predict(poly.fit_transform(X_train_scaled))\n",
    "        #y_train_pred = y_train_scaler.inverse_transform(y_train_pred_scaled)\n",
    "        y_train_pred = np.exp(y_train_pred_scaled)\n",
    "        #create a pandas series of the results\n",
    "        y_train_pred = round(pd.Series(y_train_pred, index=y_train.index, name='predicted_entries_train'),ndigits=2)\n",
    "        \n",
    "        #Add the results to the DF\n",
    "        train_df = pd.merge(left=train_df, right=y_train_pred , left_index=True, right_index=True)\n",
    "        #print(train_df.columns)\n",
    "        y_test_pred_scaled = pol_lin_reg.predict(poly.fit_transform(X_test_scaled))\n",
    "        y_test_pred = np.exp(y_test_pred_scaled)\n",
    "        #y_test_pred = y_test_scaler.inverse_transform(y_test_pred_scaled)\n",
    "        #create a pandas series of the results\n",
    "        y_test_pred = round(pd.Series(y_test_pred, index=y_test.index, name='predicted_entries_test'),ndigits=2)\n",
    "        #Add the results to the DF\n",
    "        test_df = pd.merge(left=test_df, right=y_test_pred , left_index=True, right_index=True)\n",
    "        if train_df is None and test_df is None : continue\n",
    "        train_mse = metrics.mean_squared_error(train_df[targets[index]], train_df.predicted_entries_train)\n",
    "        train_rmse = np.sqrt(metrics.mean_squared_error(train_df[targets[index]], train_df.predicted_entries_train))\n",
    "        train_mae = metrics.mean_absolute_error(train_df[targets[index]], train_df.predicted_entries_train)\n",
    "        train_std = np.std(train_df.predicted_entries_train)\n",
    "        r2_train = r2_score(train_df[targets[index]], train_df.predicted_entries_train)\n",
    "        f.write(\"Degrees: \"+str(i)+\",Target: \"+target+\"\\n\")\n",
    "        f.write(\"------ TRAIN DATA ------\\n\")\n",
    "        f.write(\"MSE : \"+str(train_mse)+\", RMSE: \"+str(train_rmse)+\", MAE : \"+str(train_mae)+\"\\n\")\n",
    "        f.write(\"R2 TRAIN \"+ str(r2_train)+\"\\n\")\n",
    "        f.write(\"TRAIN STD \"+str(train_std)+\"\\n\")\n",
    "        try:\n",
    "            test_mse = metrics.mean_squared_error(test_df[targets[index]], test_df.predicted_entries_test)\n",
    "        except: pass\n",
    "        try:\n",
    "            test_rmse = np.sqrt(metrics.mean_squared_error(test_df[targets[index]], test_df.predicted_entries_test))\n",
    "        except: pass\n",
    "        try:\n",
    "            test_mae = metrics.mean_absolute_error(test_df[targets[index]], test_df.predicted_entries_test)\n",
    "        except: pass\n",
    "        try:\n",
    "            r2_test = r2_score(test_df[targets[index]], test_df.predicted_entries_test)\n",
    "        except: pass\n",
    "        \n",
    "        test_std = np.std(test_df.predicted_entries_test)\n",
    "        f.write(\"------ TEST DATA ------\\n\")\n",
    "        f.write(\"MSE : \"+str(test_mse)+\", RMSE: \"+str(test_rmse)+\", MAE : \"+str(test_mae)+\"\\n\")\n",
    "        f.write(\"R2 TEST \"+ str(r2_test)+\"\\n\")\n",
    "        f.write(\"TEST STD \"+str(test_std)+\"\\n\")\n",
    "        f.write(\"--------------------------------\\n\")\n",
    "        \n",
    "        coeff = pol_lin_reg.coef_\n",
    "        #print(coeff)\n",
    "        #intercept = pol_lin_reg.intercept_\n",
    "        equation =\"\"+ str(pol_lin_reg.intercept_)\n",
    "        for idx in range(len(X.columns)):\n",
    "            equation += \" + \"+str(round(coeff[idx],4))+\" * \"+str(X.columns[idx])\n",
    "        new_row = {'Descripton':'weekend model ,Uni var feature selection, k=10','Degree':str(i),'Target':target,'Model_type':'POLY',\n",
    "        'Degree' : str(i),'MAE_Training':train_mae,'MSE_Training':train_mse,\n",
    "    'RMSE_Training': train_rmse,'R2_Training': r2_train,\n",
    "    'MAE_Test':test_mae,'MSE_Test':test_mse,'RMSE_Test': test_rmse,'R2_Test': r2_test,'TRAIN_STD':train_std,\n",
    "    'TEST_STD':test_std , 'EQUATION' : str(equation),'TEST_SIZE' : len(test_df),'TRAIN_SIZE':len(train_df)}\n",
    "    \n",
    "        poly_res = poly_res.append(new_row,ignore_index=True)\n",
    "        #return train_df,test_df\n",
    "    index += 1\n",
    "    f.close()\n",
    "poly_res.to_excel(\"./poly.xlsx\",index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weekend model: per site"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0a3f26f005c805b8796d2eac51f643ea47324abf4ab930a59c0414331385d455"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

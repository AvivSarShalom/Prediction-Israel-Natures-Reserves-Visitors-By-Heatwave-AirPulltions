{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n",
      "The blackcellmagic extension is already loaded. To reload it, use:\n",
      "  %reload_ext blackcellmagic\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 10;\n                var nbb_unformatted_code = \"import pandas as pd\\nimport dtale\\nimport numpy as np\\nfrom sklearn.preprocessing import PolynomialFeatures\\nimport plotly.graph_objects as go # for visualization\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn import metrics\\nimport os\\nimport statsmodels.api as sm\\n\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\n%load_ext nb_black\\n%load_ext blackcellmagic\\n\\npd.set_option('display.max_rows', 500)\\npd.set_option('display.max_columns', 500)\\npd.set_option('display.width', 1000)\";\n                var nbb_formatted_code = \"import pandas as pd\\nimport dtale\\nimport numpy as np\\nfrom sklearn.preprocessing import PolynomialFeatures\\nimport plotly.graph_objects as go  # for visualization\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn import metrics\\nimport os\\nimport statsmodels.api as sm\\n\\nimport matplotlib.pyplot as plt\\n\\n%matplotlib inline\\n\\n%load_ext nb_black\\n%load_ext blackcellmagic\\n\\npd.set_option(\\\"display.max_rows\\\", 500)\\npd.set_option(\\\"display.max_columns\\\", 500)\\npd.set_option(\\\"display.width\\\", 1000)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dtale\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import plotly.graph_objects as go # for visualization\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext nb_black\n",
    "%load_ext blackcellmagic\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 11;\n                var nbb_unformatted_code = \"df = pd.read_excel(\\\"../../../site_info_ver_3.2.xlsx\\\")\";\n                var nbb_formatted_code = \"df = pd.read_excel(\\\"../../../site_info_ver_3.2.xlsx\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_excel(\"../../../site_info_ver_3.2.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 12;\n                var nbb_unformatted_code = \"df_sites = []\\nsites = df.Site_Name.unique()\\nfor site in sites:\\n    tmp = df[df.Site_Name==site]\\n    tmp.reset_index(drop=True,inplace=True)\\n    df_sites.append(tmp)\";\n                var nbb_formatted_code = \"df_sites = []\\nsites = df.Site_Name.unique()\\nfor site in sites:\\n    tmp = df[df.Site_Name == site]\\n    tmp.reset_index(drop=True, inplace=True)\\n    df_sites.append(tmp)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_sites = []\n",
    "sites = df.Site_Name.unique()\n",
    "for site in sites:\n",
    "    tmp = df[df.Site_Name==site]\n",
    "    tmp.reset_index(drop=True,inplace=True)\n",
    "    df_sites.append(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 13;\n                var nbb_unformatted_code = \"# df.isna().sum()\\n# df=df.dropna()\\n# df.reset_index(inplace=True,drop=True)\\nfor d in df_sites:\\n    d.drop(['pm10','nox','so2','pm2.5',\\\"Site_Name\\\"],axis=1,inplace=True)\\n# len(df[df.isnull().any(axis=1)])/len(df)\";\n                var nbb_formatted_code = \"# df.isna().sum()\\n# df=df.dropna()\\n# df.reset_index(inplace=True,drop=True)\\nfor d in df_sites:\\n    d.drop([\\\"pm10\\\", \\\"nox\\\", \\\"so2\\\", \\\"pm2.5\\\", \\\"Site_Name\\\"], axis=1, inplace=True)\\n# len(df[df.isnull().any(axis=1)])/len(df)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df.isna().sum()\n",
    "# df=df.dropna()\n",
    "# df.reset_index(inplace=True,drop=True)\n",
    "for d in df_sites:\n",
    "    d.drop(['pm10','nox','so2','pm2.5',\"Site_Name\"],axis=1,inplace=True)\n",
    "# len(df[df.isnull().any(axis=1)])/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defiend X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 14;\n                var nbb_unformatted_code = \"X_site = []\\ntargets_site = []\\nfor d in df_sites:\\n    X_site.append(d.drop(['Israelis_Count','Tourists_Count','Total',\\\"Date\\\",\\\"Model_number\\\"],axis=1))\\n    targets_site.append(d[['Israelis_Count','Tourists_Count','Total']])\";\n                var nbb_formatted_code = \"X_site = []\\ntargets_site = []\\nfor d in df_sites:\\n    X_site.append(\\n        d.drop(\\n            [\\\"Israelis_Count\\\", \\\"Tourists_Count\\\", \\\"Total\\\", \\\"Date\\\", \\\"Model_number\\\"],\\n            axis=1,\\n        )\\n    )\\n    targets_site.append(d[[\\\"Israelis_Count\\\", \\\"Tourists_Count\\\", \\\"Total\\\"]])\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_site = []\n",
    "targets_site = []\n",
    "for d in df_sites:\n",
    "    X_site.append(d.drop(['Israelis_Count','Tourists_Count','Total',\"Date\",\"Model_number\"],axis=1))\n",
    "    targets_site.append(d[['Israelis_Count','Tourists_Count','Total']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaleing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 15;\n                var nbb_unformatted_code = \"from sklearn.preprocessing import MinMaxScaler\\nscaled_X_sites=[]\\nscaled_targets_sites=[]\\nfor i in range(len(X_site)):\\n    #scale X\\n    scaler = MinMaxScaler()\\n    scaled_X_sites.append( pd.DataFrame(scaler.fit_transform(X_site[i]), columns=X_site[i].columns))\\n\\n    #scale y\\n    scaled_targets_sites.append( np.log(targets_site[i]+0.01))\";\n                var nbb_formatted_code = \"from sklearn.preprocessing import MinMaxScaler\\n\\nscaled_X_sites = []\\nscaled_targets_sites = []\\nfor i in range(len(X_site)):\\n    # scale X\\n    scaler = MinMaxScaler()\\n    scaled_X_sites.append(\\n        pd.DataFrame(scaler.fit_transform(X_site[i]), columns=X_site[i].columns)\\n    )\\n\\n    # scale y\\n    scaled_targets_sites.append(np.log(targets_site[i] + 0.01))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaled_X_sites=[]\n",
    "scaled_targets_sites=[]\n",
    "for i in range(len(X_site)):\n",
    "    #scale X\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_X_sites.append( pd.DataFrame(scaler.fit_transform(X_site[i]), columns=X_site[i].columns))\n",
    "\n",
    "    #scale y\n",
    "    scaled_targets_sites.append( np.log(targets_site[i]+0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 16;\n                var nbb_unformatted_code = \"# c = ['hsl('+str(h)+',50%'+',50%)' for h in np.linspace(0, 360, len(scaled_targets_sites[0].columns))]\\n# fig = go.Figure()\\n# fig.add_traces(data=[go.Box( \\n#     y=scaled_targets_sites[0].iloc[:, i], \\n#     marker_color=c[i],\\n#     name=scaled_targets_sites[0].columns[i])\\n#     for i in range(len(scaled_targets_sites[0].columns))\\n#     ])\";\n                var nbb_formatted_code = \"# c = ['hsl('+str(h)+',50%'+',50%)' for h in np.linspace(0, 360, len(scaled_targets_sites[0].columns))]\\n# fig = go.Figure()\\n# fig.add_traces(data=[go.Box(\\n#     y=scaled_targets_sites[0].iloc[:, i],\\n#     marker_color=c[i],\\n#     name=scaled_targets_sites[0].columns[i])\\n#     for i in range(len(scaled_targets_sites[0].columns))\\n#     ])\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# c = ['hsl('+str(h)+',50%'+',50%)' for h in np.linspace(0, 360, len(scaled_targets_sites[0].columns))]\n",
    "# fig = go.Figure()\n",
    "# fig.add_traces(data=[go.Box( \n",
    "#     y=scaled_targets_sites[0].iloc[:, i], \n",
    "#     marker_color=c[i],\n",
    "#     name=scaled_targets_sites[0].columns[i])\n",
    "#     for i in range(len(scaled_targets_sites[0].columns))\n",
    "#     ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 17;\n                var nbb_unformatted_code = \"outliers_I_sites=[]\\noutliers_To_sites=[]\\noutliers_Tu_sites=[]\\n\\nfor j in range(len(scaled_targets_sites)):\\n    plt.cla()\\n    data=[scaled_targets_sites[j].Israelis_Count,scaled_targets_sites[j].Total,scaled_targets_sites[j].Tourists_Count]\\n    bp = plt.boxplot(data)\\n    minimums = [round(item.get_ydata()[0], 4) for item in bp['caps']][::2]\\n    maximums = [round(item.get_ydata()[0], 4) for item in bp['caps']][1::2]\\n    outliers_I_sites.append ( scaled_targets_sites[j][(scaled_targets_sites[j].Israelis_Count>maximums[0])  | (scaled_targets_sites[j].Israelis_Count<minimums[0])].index)\\n    outliers_To_sites.append (scaled_targets_sites[j][(scaled_targets_sites[j].Total>maximums[1]) | (scaled_targets_sites[j].Total<minimums[1])].index)\\n    outliers_Tu_sites.append (scaled_targets_sites[j][(scaled_targets_sites[j].Tourists_Count>maximums[2]) | (scaled_targets_sites[j].Tourists_Count<minimums[2])].index)\";\n                var nbb_formatted_code = \"outliers_I_sites = []\\noutliers_To_sites = []\\noutliers_Tu_sites = []\\n\\nfor j in range(len(scaled_targets_sites)):\\n    plt.cla()\\n    data = [\\n        scaled_targets_sites[j].Israelis_Count,\\n        scaled_targets_sites[j].Total,\\n        scaled_targets_sites[j].Tourists_Count,\\n    ]\\n    bp = plt.boxplot(data)\\n    minimums = [round(item.get_ydata()[0], 4) for item in bp[\\\"caps\\\"]][::2]\\n    maximums = [round(item.get_ydata()[0], 4) for item in bp[\\\"caps\\\"]][1::2]\\n    outliers_I_sites.append(\\n        scaled_targets_sites[j][\\n            (scaled_targets_sites[j].Israelis_Count > maximums[0])\\n            | (scaled_targets_sites[j].Israelis_Count < minimums[0])\\n        ].index\\n    )\\n    outliers_To_sites.append(\\n        scaled_targets_sites[j][\\n            (scaled_targets_sites[j].Total > maximums[1])\\n            | (scaled_targets_sites[j].Total < minimums[1])\\n        ].index\\n    )\\n    outliers_Tu_sites.append(\\n        scaled_targets_sites[j][\\n            (scaled_targets_sites[j].Tourists_Count > maximums[2])\\n            | (scaled_targets_sites[j].Tourists_Count < minimums[2])\\n        ].index\\n    )\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outliers_I_sites=[]\n",
    "outliers_To_sites=[]\n",
    "outliers_Tu_sites=[]\n",
    "\n",
    "for j in range(len(scaled_targets_sites)):\n",
    "    plt.cla()\n",
    "    data=[scaled_targets_sites[j].Israelis_Count,scaled_targets_sites[j].Total,scaled_targets_sites[j].Tourists_Count]\n",
    "    bp = plt.boxplot(data)\n",
    "    minimums = [round(item.get_ydata()[0], 4) for item in bp['caps']][::2]\n",
    "    maximums = [round(item.get_ydata()[0], 4) for item in bp['caps']][1::2]\n",
    "    outliers_I_sites.append ( scaled_targets_sites[j][(scaled_targets_sites[j].Israelis_Count>maximums[0])  | (scaled_targets_sites[j].Israelis_Count<minimums[0])].index)\n",
    "    outliers_To_sites.append (scaled_targets_sites[j][(scaled_targets_sites[j].Total>maximums[1]) | (scaled_targets_sites[j].Total<minimums[1])].index)\n",
    "    outliers_Tu_sites.append (scaled_targets_sites[j][(scaled_targets_sites[j].Tourists_Count>maximums[2]) | (scaled_targets_sites[j].Tourists_Count<minimums[2])].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model MLR with Pollutions droped Null rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexander Stream-Bet Yannai\n",
      "1013 1013 46\n",
      "1013 1013 46\n",
      "1059 1059 46\n",
      "Apollonia\n",
      "1902 1902 14\n",
      "1895 1895 14\n",
      "1909 1909 14\n",
      "Arbel\n",
      "1876 1876 48\n",
      "1866 1866 48\n",
      "1914 1914 48\n",
      "Avdat\n",
      "1885 1885 20\n",
      "1878 1878 20\n",
      "1898 1898 20\n",
      "Ayun Stream\n",
      "1896 1896 22\n",
      "1897 1897 22\n",
      "1919 1919 22\n",
      "Bet Alpha\n",
      "1691 1691 31\n",
      "1695 1695 31\n",
      "1726 1726 31\n",
      "Bet Guvrin\n",
      "1892 1892 27\n",
      "1880 1880 27\n",
      "1907 1907 27\n",
      "Bet Shean\n",
      "1865 1865 69\n",
      "1846 1846 69\n",
      "1915 1915 69\n",
      "Bet Shearim\n",
      "1771 1771 35\n",
      "1770 1770 35\n",
      "1805 1805 35\n",
      "Caesarea\n",
      "1865 1865 98\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14092/1313557705.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    136\u001b[0m       \u001b[1;31m#  ACC_Test = round(correct_rows/len(test_df),3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m       \u001b[0mMSE_Test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtargets_list_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Predicted_test_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtargets_list_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m       \u001b[0mRMSE_Test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtargets_list_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Predicted_test_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtargets_list_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m       \u001b[0mMAE_Test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtargets_list_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Predicted_test_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtargets_list_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;36m0.825\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \"\"\"\n\u001b[1;32m--> 335\u001b[1;33m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[0;32m    336\u001b[0m         y_true, y_pred, multioutput)\n\u001b[0;32m    337\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    721\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 18;\n                var nbb_unformatted_code = \"Model_type= \\\"MLR\\\"\\nres=pd.read_excel(\\\"../../../res.xlsx\\\")\\n\\n\\nfor j in range(len(scaled_X_sites)):\\n  Descripton = \\\"Without Pollutions Without outliers for each site \\\" + sites[j]\\n  print(sites[j])\\n  targets = [scaled_targets_sites[j].Israelis_Count,scaled_targets_sites[j].Total,scaled_targets_sites[j].Tourists_Count] # get target info of this site\\n  targets_list_name = ['Israelis_Count','Total','Tourists_Count']\\n  idx=0\\n  for y in targets:\\n\\n      #split the data, train the model and get prediction for the training and for the test  \\n      #######################################################################################################################\\n      X=scaled_X_sites[j] # get X info of this site\\n      # for outliers \\n      if idx==0:\\n        X=X.drop(outliers_I_sites[j])\\n        y.drop(outliers_I_sites[j],inplace=True)\\n      elif idx==1:\\n        X=X.drop(outliers_To_sites[j])\\n        y.drop(outliers_To_sites[j],inplace=True)\\n      # else :\\n      #   X=X.drop(outliers_Tu_sites[j])\\n      #   y.drop(outliers_Tu_sites[j],inplace=True)\\n      print(len(X),len(y),len(outliers_To_sites[j]))\\n      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=312148513)\\n      train_df_scaled = pd.merge(left=X_train, right=y_train, left_index=True, right_index=True)\\n      test_df_scaled = pd.merge(left=X_test, right=y_test, left_index=True, right_index=True)\\n\\n      lm = LinearRegression()  # define our model using least square method\\n      lm.fit(X_train,y_train)   # Fit our linear model\\n\\n      #train\\n      fitted = np.exp(lm.predict(X_train))\\n      predicted_train = round(pd.Series(fitted, index=y_train.index, name='Predicted_train_'+targets_list_name[idx]),ndigits=2)\\n      orignal_train=np.exp(train_df_scaled[[targets_list_name[idx]]])\\n      train_df = pd.merge(left=orignal_train, right=predicted_train, left_index=True, right_index=True)\\n      train_df\\n\\n      #test\\n      fitted = np.exp(lm.predict(X_test))\\n      predicted_test = round(pd.Series(fitted, index=y_test.index, name='Predicted_test_'+targets_list_name[idx]),ndigits=2)\\n      orignal_test = np.exp(test_df_scaled[[targets_list_name[idx]]])\\n      test_df = pd.merge(left=orignal_test, right=predicted_test, left_index=True, right_index=True)\\n      test_df\\n       #######################################################################################################################\\n\\n\\n\\n\\n\\n       #plot the residuals graph\\n       #######################################################################################################################\\n\\n       #calculate the residuals\\n      test_df['residuals'] = test_df['Predicted_test_'+targets_list_name[idx]] - test_df[targets_list_name[idx]]\\n      train_df['residuals'] = train_df['Predicted_train_'+targets_list_name[idx]] - train_df[targets_list_name[idx]]\\n\\n      fig= go.Figure()\\n      fig.add_trace(\\n        go.Scatter(\\n            x=train_df['Predicted_train_'+targets_list_name[idx]],\\n            y=train_df.residuals,\\n            mode='markers',\\n            name='train residuals',\\n            marker_color='blue',\\n            marker_size=1.5,\\n            marker_line_width=0,\\n         )\\n       )\\n      fig.add_trace(\\n        go.Scatter(\\n            x=test_df['Predicted_test_'+targets_list_name[idx]],\\n            y=test_df.residuals,\\n            mode='markers',\\n            name='test residuals',\\n            marker_color='red',\\n            marker_size=1.5,\\n            marker_line_width=0,\\n         )\\n       )\\n      fig.add_trace(\\n         go.Scatter(\\n            x=test_df['Predicted_test_'+targets_list_name[idx]],\\n            y=test_df.residuals*0,\\n            mode='lines',\\n            name='zero line',\\n            marker_color='black',\\n            marker_size=1.5,\\n            marker_line_width=0,\\n         )\\n       )\\n      fig.update_layout(\\n          title=\\\"Residuals of Predicted \\\"+targets_list_name[idx],\\n          xaxis_title=\\\"Predicted \\\"+targets_list_name[idx],\\n          yaxis_title=\\\"Residuals\\\",\\n          font=dict(\\n              size=14,\\n              color=\\\"RebeccaPurple\\\"\\n          )\\n      )\\n      # fig.show()\\n       #######################################################################################################################\\n\\n       #create folder\\n       ########################################\\n      if not os.path.exists(sites[j]):\\n        os.mkdir(sites[j])\\n\\n      if not os.path.exists(sites[j]+'/'+Descripton):\\n        os.mkdir(sites[j]+'/'+Descripton)\\n      fig.write_image(sites[j]+'/'+Descripton+\\\"/results_\\\"+targets_list_name[idx]+'_.png', width=1500, height=600)\\n      #########################################\\n\\n      #create txt file with the metrix result \\n      ################################################################################################################################################     \\n      f = open(sites[j]+'/'+Descripton+\\\"/results_\\\"+targets_list_name[idx]+'_.txt', 'w')\\n\\n      #  correct_rows = train_df.loc[abs(train_df['Predicted_train_'+targets_list_name[idx]]-train_df[targets_list_name[idx]])<=50].any(axis=1).count()\\n      #  ACC_Training = round(correct_rows/len(train_df),3)\\n\\n      MSE_Training = metrics.mean_squared_error(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]])\\n      RMSE_Training = np.sqrt(metrics.mean_squared_error(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]]))\\n      MAE_Training = metrics.mean_absolute_error(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]])\\n      R2_Training=metrics.r2_score(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]])\\n      std_Training = np.std(predicted_train)\\n\\n      f.write(\\\"------ TRAIN DATA ------\\\\n\\\")\\n      #f.write(\\\"Model \\\"+' mod0' +\\\" Accuracy: \\\"+str(ACC_Training)+\\\"\\\\n\\\")\\n      f.write(\\\"MSE : \\\"+str(MSE_Training)+\\\", RMSE: \\\"+str(RMSE_Training)+\\\", MAE : \\\"+str(MAE_Training)+\\\"\\\\n\\\")\\n      f.write(\\\"R2 TRAIN \\\"+ str(R2_Training)+\\\"\\\\n\\\")\\n\\n\\n      #  correct_rows = test_df.loc[abs(test_df['Predicted_test_'+targets_list_name[idx]]-test_df[targets_list_name[idx]])<=50].any(axis=1).count()\\n      #  ACC_Test = round(correct_rows/len(test_df),3)\\n\\n      MSE_Test = metrics.mean_squared_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\\n      RMSE_Test = np.sqrt(metrics.mean_squared_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]]))\\n      MAE_Test = metrics.mean_absolute_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\\n      R2_Test = metrics.r2_score(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\\n      std_test = np.std(predicted_test)\\n\\n      f.write(\\\"\\\\n\\\")\\n      f.write(\\\"------ TEST DATA ------\\\\n\\\")\\n      #f.write(\\\"Model \\\"+' mod0' +\\\" Accuracy: \\\"+str(ACC_Test)+\\\"\\\\n\\\")\\n      f.write(\\\"MSE : \\\"+str(MSE_Test)+\\\", RMSE: \\\"+str(RMSE_Test)+\\\", MAE : \\\"+str(MAE_Test)+\\\"\\\\n\\\")\\n      f.write(\\\"R2 TEST \\\"+ str(R2_Test)+\\\"\\\\n\\\")\\n      f.write(\\\"--------------------------------\\\\n\\\")\\n\\n      f.close()\\n      ################################################################################################################################################     \\n\\n      #Add to excel result the new line\\n      ################################################################################################################################################\\n      Target=targets_list_name[idx]\\n      Site_in_this_model=sites[j]\\n      new_row = {\\n        'Descripton':Descripton,\\n        \\\"Target\\\":Target,\\n        'Model_type':Model_type,\\n        # 'Model_number':Model_number,\\n        'Site_in_this_model':Site_in_this_model,\\n        \\\"Size Train\\\":len(train_df),\\n        # 'ACC_Training':ACC_Training,\\n        'MAE_Training':MAE_Training,\\n        'MSE_Training':MSE_Training,\\n        'RMSE_Training':RMSE_Training,\\n        'STD_Training':std_Training,\\n        'R2_Training':R2_Training,\\n        \\\"Size Test\\\":len(test_df),\\n        # 'ACC_Test':ACC_Test,\\n        'MAE_Test':MAE_Test,\\n        'MSE_Test':MSE_Test,\\n        'RMSE_Test':RMSE_Test,\\n        'STD_Test':std_test,\\n        'R2_Test':R2_Test \\n        }\\n\\n      res = res.append(new_row,ignore_index=True)\\n      ################################################################################################################################################     \\n\\n      # Index for the next target y\\n      idx+=1\\n\\n\\nres.to_excel(\\\"../../../res.xlsx\\\",index=False)\";\n                var nbb_formatted_code = \"Model_type = \\\"MLR\\\"\\nres = pd.read_excel(\\\"../../../res.xlsx\\\")\\n\\n\\nfor j in range(len(scaled_X_sites)):\\n    Descripton = \\\"Without Pollutions Without outliers for each site \\\" + sites[j]\\n    print(sites[j])\\n    targets = [\\n        scaled_targets_sites[j].Israelis_Count,\\n        scaled_targets_sites[j].Total,\\n        scaled_targets_sites[j].Tourists_Count,\\n    ]  # get target info of this site\\n    targets_list_name = [\\\"Israelis_Count\\\", \\\"Total\\\", \\\"Tourists_Count\\\"]\\n    idx = 0\\n    for y in targets:\\n\\n        # split the data, train the model and get prediction for the training and for the test\\n        #######################################################################################################################\\n        X = scaled_X_sites[j]  # get X info of this site\\n        # for outliers\\n        if idx == 0:\\n            X = X.drop(outliers_I_sites[j])\\n            y.drop(outliers_I_sites[j], inplace=True)\\n        elif idx == 1:\\n            X = X.drop(outliers_To_sites[j])\\n            y.drop(outliers_To_sites[j], inplace=True)\\n        # else :\\n        #   X=X.drop(outliers_Tu_sites[j])\\n        #   y.drop(outliers_Tu_sites[j],inplace=True)\\n        print(len(X), len(y), len(outliers_To_sites[j]))\\n        X_train, X_test, y_train, y_test = train_test_split(\\n            X, y, test_size=0.3, random_state=312148513\\n        )\\n        train_df_scaled = pd.merge(\\n            left=X_train, right=y_train, left_index=True, right_index=True\\n        )\\n        test_df_scaled = pd.merge(\\n            left=X_test, right=y_test, left_index=True, right_index=True\\n        )\\n\\n        lm = LinearRegression()  # define our model using least square method\\n        lm.fit(X_train, y_train)  # Fit our linear model\\n\\n        # train\\n        fitted = np.exp(lm.predict(X_train))\\n        predicted_train = round(\\n            pd.Series(\\n                fitted,\\n                index=y_train.index,\\n                name=\\\"Predicted_train_\\\" + targets_list_name[idx],\\n            ),\\n            ndigits=2,\\n        )\\n        orignal_train = np.exp(train_df_scaled[[targets_list_name[idx]]])\\n        train_df = pd.merge(\\n            left=orignal_train, right=predicted_train, left_index=True, right_index=True\\n        )\\n        train_df\\n\\n        # test\\n        fitted = np.exp(lm.predict(X_test))\\n        predicted_test = round(\\n            pd.Series(\\n                fitted,\\n                index=y_test.index,\\n                name=\\\"Predicted_test_\\\" + targets_list_name[idx],\\n            ),\\n            ndigits=2,\\n        )\\n        orignal_test = np.exp(test_df_scaled[[targets_list_name[idx]]])\\n        test_df = pd.merge(\\n            left=orignal_test, right=predicted_test, left_index=True, right_index=True\\n        )\\n        test_df\\n        #######################################################################################################################\\n\\n        # plot the residuals graph\\n        #######################################################################################################################\\n\\n        # calculate the residuals\\n        test_df[\\\"residuals\\\"] = (\\n            test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]]\\n            - test_df[targets_list_name[idx]]\\n        )\\n        train_df[\\\"residuals\\\"] = (\\n            train_df[\\\"Predicted_train_\\\" + targets_list_name[idx]]\\n            - train_df[targets_list_name[idx]]\\n        )\\n\\n        fig = go.Figure()\\n        fig.add_trace(\\n            go.Scatter(\\n                x=train_df[\\\"Predicted_train_\\\" + targets_list_name[idx]],\\n                y=train_df.residuals,\\n                mode=\\\"markers\\\",\\n                name=\\\"train residuals\\\",\\n                marker_color=\\\"blue\\\",\\n                marker_size=1.5,\\n                marker_line_width=0,\\n            )\\n        )\\n        fig.add_trace(\\n            go.Scatter(\\n                x=test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]],\\n                y=test_df.residuals,\\n                mode=\\\"markers\\\",\\n                name=\\\"test residuals\\\",\\n                marker_color=\\\"red\\\",\\n                marker_size=1.5,\\n                marker_line_width=0,\\n            )\\n        )\\n        fig.add_trace(\\n            go.Scatter(\\n                x=test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]],\\n                y=test_df.residuals * 0,\\n                mode=\\\"lines\\\",\\n                name=\\\"zero line\\\",\\n                marker_color=\\\"black\\\",\\n                marker_size=1.5,\\n                marker_line_width=0,\\n            )\\n        )\\n        fig.update_layout(\\n            title=\\\"Residuals of Predicted \\\" + targets_list_name[idx],\\n            xaxis_title=\\\"Predicted \\\" + targets_list_name[idx],\\n            yaxis_title=\\\"Residuals\\\",\\n            font=dict(size=14, color=\\\"RebeccaPurple\\\"),\\n        )\\n        # fig.show()\\n        #######################################################################################################################\\n\\n        # create folder\\n        ########################################\\n        if not os.path.exists(sites[j]):\\n            os.mkdir(sites[j])\\n\\n        if not os.path.exists(sites[j] + \\\"/\\\" + Descripton):\\n            os.mkdir(sites[j] + \\\"/\\\" + Descripton)\\n        fig.write_image(\\n            sites[j]\\n            + \\\"/\\\"\\n            + Descripton\\n            + \\\"/results_\\\"\\n            + targets_list_name[idx]\\n            + \\\"_.png\\\",\\n            width=1500,\\n            height=600,\\n        )\\n        #########################################\\n\\n        # create txt file with the metrix result\\n        ################################################################################################################################################\\n        f = open(\\n            sites[j]\\n            + \\\"/\\\"\\n            + Descripton\\n            + \\\"/results_\\\"\\n            + targets_list_name[idx]\\n            + \\\"_.txt\\\",\\n            \\\"w\\\",\\n        )\\n\\n        #  correct_rows = train_df.loc[abs(train_df['Predicted_train_'+targets_list_name[idx]]-train_df[targets_list_name[idx]])<=50].any(axis=1).count()\\n        #  ACC_Training = round(correct_rows/len(train_df),3)\\n\\n        MSE_Training = metrics.mean_squared_error(\\n            train_df[targets_list_name[idx]],\\n            train_df[\\\"Predicted_train_\\\" + targets_list_name[idx]],\\n        )\\n        RMSE_Training = np.sqrt(\\n            metrics.mean_squared_error(\\n                train_df[targets_list_name[idx]],\\n                train_df[\\\"Predicted_train_\\\" + targets_list_name[idx]],\\n            )\\n        )\\n        MAE_Training = metrics.mean_absolute_error(\\n            train_df[targets_list_name[idx]],\\n            train_df[\\\"Predicted_train_\\\" + targets_list_name[idx]],\\n        )\\n        R2_Training = metrics.r2_score(\\n            train_df[targets_list_name[idx]],\\n            train_df[\\\"Predicted_train_\\\" + targets_list_name[idx]],\\n        )\\n        std_Training = np.std(predicted_train)\\n\\n        f.write(\\\"------ TRAIN DATA ------\\\\n\\\")\\n        # f.write(\\\"Model \\\"+' mod0' +\\\" Accuracy: \\\"+str(ACC_Training)+\\\"\\\\n\\\")\\n        f.write(\\n            \\\"MSE : \\\"\\n            + str(MSE_Training)\\n            + \\\", RMSE: \\\"\\n            + str(RMSE_Training)\\n            + \\\", MAE : \\\"\\n            + str(MAE_Training)\\n            + \\\"\\\\n\\\"\\n        )\\n        f.write(\\\"R2 TRAIN \\\" + str(R2_Training) + \\\"\\\\n\\\")\\n\\n        #  correct_rows = test_df.loc[abs(test_df['Predicted_test_'+targets_list_name[idx]]-test_df[targets_list_name[idx]])<=50].any(axis=1).count()\\n        #  ACC_Test = round(correct_rows/len(test_df),3)\\n\\n        MSE_Test = metrics.mean_squared_error(\\n            test_df[targets_list_name[idx]],\\n            test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]],\\n        )\\n        RMSE_Test = np.sqrt(\\n            metrics.mean_squared_error(\\n                test_df[targets_list_name[idx]],\\n                test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]],\\n            )\\n        )\\n        MAE_Test = metrics.mean_absolute_error(\\n            test_df[targets_list_name[idx]],\\n            test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]],\\n        )\\n        R2_Test = metrics.r2_score(\\n            test_df[targets_list_name[idx]],\\n            test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]],\\n        )\\n        std_test = np.std(predicted_test)\\n\\n        f.write(\\\"\\\\n\\\")\\n        f.write(\\\"------ TEST DATA ------\\\\n\\\")\\n        # f.write(\\\"Model \\\"+' mod0' +\\\" Accuracy: \\\"+str(ACC_Test)+\\\"\\\\n\\\")\\n        f.write(\\n            \\\"MSE : \\\"\\n            + str(MSE_Test)\\n            + \\\", RMSE: \\\"\\n            + str(RMSE_Test)\\n            + \\\", MAE : \\\"\\n            + str(MAE_Test)\\n            + \\\"\\\\n\\\"\\n        )\\n        f.write(\\\"R2 TEST \\\" + str(R2_Test) + \\\"\\\\n\\\")\\n        f.write(\\\"--------------------------------\\\\n\\\")\\n\\n        f.close()\\n        ################################################################################################################################################\\n\\n        # Add to excel result the new line\\n        ################################################################################################################################################\\n        Target = targets_list_name[idx]\\n        Site_in_this_model = sites[j]\\n        new_row = {\\n            \\\"Descripton\\\": Descripton,\\n            \\\"Target\\\": Target,\\n            \\\"Model_type\\\": Model_type,\\n            # 'Model_number':Model_number,\\n            \\\"Site_in_this_model\\\": Site_in_this_model,\\n            \\\"Size Train\\\": len(train_df),\\n            # 'ACC_Training':ACC_Training,\\n            \\\"MAE_Training\\\": MAE_Training,\\n            \\\"MSE_Training\\\": MSE_Training,\\n            \\\"RMSE_Training\\\": RMSE_Training,\\n            \\\"STD_Training\\\": std_Training,\\n            \\\"R2_Training\\\": R2_Training,\\n            \\\"Size Test\\\": len(test_df),\\n            # 'ACC_Test':ACC_Test,\\n            \\\"MAE_Test\\\": MAE_Test,\\n            \\\"MSE_Test\\\": MSE_Test,\\n            \\\"RMSE_Test\\\": RMSE_Test,\\n            \\\"STD_Test\\\": std_test,\\n            \\\"R2_Test\\\": R2_Test,\\n        }\\n\\n        res = res.append(new_row, ignore_index=True)\\n        ################################################################################################################################################\\n\\n        # Index for the next target y\\n        idx += 1\\n\\n\\nres.to_excel(\\\"../../../res.xlsx\\\", index=False)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Model_type= \"MLR\"\n",
    "res=pd.read_excel(\"../../../res.xlsx\")\n",
    "\n",
    "\n",
    "for j in range(len(scaled_X_sites)):\n",
    "  Descripton = \"Without Pollutions Without outliers for each site \" + sites[j]\n",
    "  print(sites[j])\n",
    "  targets = [scaled_targets_sites[j].Israelis_Count,scaled_targets_sites[j].Total,scaled_targets_sites[j].Tourists_Count] # get target info of this site\n",
    "  targets_list_name = ['Israelis_Count','Total','Tourists_Count']\n",
    "  idx=0\n",
    "  for y in targets:\n",
    "\n",
    "      #split the data, train the model and get prediction for the training and for the test  \n",
    "      #######################################################################################################################\n",
    "      X=scaled_X_sites[j] # get X info of this site\n",
    "      # for outliers \n",
    "      if idx==0:\n",
    "        X=X.drop(outliers_I_sites[j])\n",
    "        y.drop(outliers_I_sites[j],inplace=True)\n",
    "      elif idx==1:\n",
    "        X=X.drop(outliers_To_sites[j])\n",
    "        y.drop(outliers_To_sites[j],inplace=True)\n",
    "      # else :\n",
    "      #   X=X.drop(outliers_Tu_sites[j])\n",
    "      #   y.drop(outliers_Tu_sites[j],inplace=True)\n",
    "      print(len(X),len(y),len(outliers_To_sites[j]))\n",
    "      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=312148513)\n",
    "      train_df_scaled = pd.merge(left=X_train, right=y_train, left_index=True, right_index=True)\n",
    "      test_df_scaled = pd.merge(left=X_test, right=y_test, left_index=True, right_index=True)\n",
    "\n",
    "      lm = LinearRegression()  # define our model using least square method\n",
    "      lm.fit(X_train,y_train)   # Fit our linear model\n",
    "\n",
    "      #train\n",
    "      fitted = np.exp(lm.predict(X_train))\n",
    "      predicted_train = round(pd.Series(fitted, index=y_train.index, name='Predicted_train_'+targets_list_name[idx]),ndigits=2)\n",
    "      orignal_train=np.exp(train_df_scaled[[targets_list_name[idx]]])\n",
    "      train_df = pd.merge(left=orignal_train, right=predicted_train, left_index=True, right_index=True)\n",
    "      train_df\n",
    "\n",
    "      #test\n",
    "      fitted = np.exp(lm.predict(X_test))\n",
    "      predicted_test = round(pd.Series(fitted, index=y_test.index, name='Predicted_test_'+targets_list_name[idx]),ndigits=2)\n",
    "      orignal_test = np.exp(test_df_scaled[[targets_list_name[idx]]])\n",
    "      test_df = pd.merge(left=orignal_test, right=predicted_test, left_index=True, right_index=True)\n",
    "      test_df\n",
    "       #######################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "       #plot the residuals graph\n",
    "       #######################################################################################################################\n",
    "\n",
    "       #calculate the residuals\n",
    "      test_df['residuals'] = test_df['Predicted_test_'+targets_list_name[idx]] - test_df[targets_list_name[idx]]\n",
    "      train_df['residuals'] = train_df['Predicted_train_'+targets_list_name[idx]] - train_df[targets_list_name[idx]]\n",
    "\n",
    "      fig= go.Figure()\n",
    "      fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=train_df['Predicted_train_'+targets_list_name[idx]],\n",
    "            y=train_df.residuals,\n",
    "            mode='markers',\n",
    "            name='train residuals',\n",
    "            marker_color='blue',\n",
    "            marker_size=1.5,\n",
    "            marker_line_width=0,\n",
    "         )\n",
    "       )\n",
    "      fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=test_df['Predicted_test_'+targets_list_name[idx]],\n",
    "            y=test_df.residuals,\n",
    "            mode='markers',\n",
    "            name='test residuals',\n",
    "            marker_color='red',\n",
    "            marker_size=1.5,\n",
    "            marker_line_width=0,\n",
    "         )\n",
    "       )\n",
    "      fig.add_trace(\n",
    "         go.Scatter(\n",
    "            x=test_df['Predicted_test_'+targets_list_name[idx]],\n",
    "            y=test_df.residuals*0,\n",
    "            mode='lines',\n",
    "            name='zero line',\n",
    "            marker_color='black',\n",
    "            marker_size=1.5,\n",
    "            marker_line_width=0,\n",
    "         )\n",
    "       )\n",
    "      fig.update_layout(\n",
    "          title=\"Residuals of Predicted \"+targets_list_name[idx],\n",
    "          xaxis_title=\"Predicted \"+targets_list_name[idx],\n",
    "          yaxis_title=\"Residuals\",\n",
    "          font=dict(\n",
    "              size=14,\n",
    "              color=\"RebeccaPurple\"\n",
    "          )\n",
    "      )\n",
    "      # fig.show()\n",
    "       #######################################################################################################################\n",
    "\n",
    "       #create folder\n",
    "       ########################################\n",
    "      if not os.path.exists(sites[j]):\n",
    "        os.mkdir(sites[j])\n",
    "\n",
    "      if not os.path.exists(sites[j]+'/'+Descripton):\n",
    "        os.mkdir(sites[j]+'/'+Descripton)\n",
    "      fig.write_image(sites[j]+'/'+Descripton+\"/results_\"+targets_list_name[idx]+'_.png', width=1500, height=600)\n",
    "      #########################################\n",
    "\n",
    "      #create txt file with the metrix result \n",
    "      ################################################################################################################################################     \n",
    "      f = open(sites[j]+'/'+Descripton+\"/results_\"+targets_list_name[idx]+'_.txt', 'w')\n",
    "\n",
    "      #  correct_rows = train_df.loc[abs(train_df['Predicted_train_'+targets_list_name[idx]]-train_df[targets_list_name[idx]])<=50].any(axis=1).count()\n",
    "      #  ACC_Training = round(correct_rows/len(train_df),3)\n",
    "\n",
    "      MSE_Training = metrics.mean_squared_error(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]])\n",
    "      RMSE_Training = np.sqrt(metrics.mean_squared_error(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]]))\n",
    "      MAE_Training = metrics.mean_absolute_error(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]])\n",
    "      R2_Training=metrics.r2_score(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]])\n",
    "      std_Training = np.std(predicted_train)\n",
    "\n",
    "      f.write(\"------ TRAIN DATA ------\\n\")\n",
    "      #f.write(\"Model \"+' mod0' +\" Accuracy: \"+str(ACC_Training)+\"\\n\")\n",
    "      f.write(\"MSE : \"+str(MSE_Training)+\", RMSE: \"+str(RMSE_Training)+\", MAE : \"+str(MAE_Training)+\"\\n\")\n",
    "      f.write(\"R2 TRAIN \"+ str(R2_Training)+\"\\n\")\n",
    "\n",
    "\n",
    "      #  correct_rows = test_df.loc[abs(test_df['Predicted_test_'+targets_list_name[idx]]-test_df[targets_list_name[idx]])<=50].any(axis=1).count()\n",
    "      #  ACC_Test = round(correct_rows/len(test_df),3)\n",
    "\n",
    "      MSE_Test = metrics.mean_squared_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\n",
    "      RMSE_Test = np.sqrt(metrics.mean_squared_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]]))\n",
    "      MAE_Test = metrics.mean_absolute_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\n",
    "      R2_Test = metrics.r2_score(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\n",
    "      std_test = np.std(predicted_test)\n",
    "\n",
    "      f.write(\"\\n\")\n",
    "      f.write(\"------ TEST DATA ------\\n\")\n",
    "      #f.write(\"Model \"+' mod0' +\" Accuracy: \"+str(ACC_Test)+\"\\n\")\n",
    "      f.write(\"MSE : \"+str(MSE_Test)+\", RMSE: \"+str(RMSE_Test)+\", MAE : \"+str(MAE_Test)+\"\\n\")\n",
    "      f.write(\"R2 TEST \"+ str(R2_Test)+\"\\n\")\n",
    "      f.write(\"--------------------------------\\n\")\n",
    "\n",
    "      f.close()\n",
    "      ################################################################################################################################################     \n",
    "\n",
    "      #Add to excel result the new line\n",
    "      ################################################################################################################################################\n",
    "      Target=targets_list_name[idx]\n",
    "      Site_in_this_model=sites[j]\n",
    "      new_row = {\n",
    "        'Descripton':Descripton,\n",
    "        \"Target\":Target,\n",
    "        'Model_type':Model_type,\n",
    "        # 'Model_number':Model_number,\n",
    "        'Site_in_this_model':Site_in_this_model,\n",
    "        \"Size Train\":len(train_df),\n",
    "        # 'ACC_Training':ACC_Training,\n",
    "        'MAE_Training':MAE_Training,\n",
    "        'MSE_Training':MSE_Training,\n",
    "        'RMSE_Training':RMSE_Training,\n",
    "        'STD_Training':std_Training,\n",
    "        'R2_Training':R2_Training,\n",
    "        \"Size Test\":len(test_df),\n",
    "        # 'ACC_Test':ACC_Test,\n",
    "        'MAE_Test':MAE_Test,\n",
    "        'MSE_Test':MSE_Test,\n",
    "        'RMSE_Test':RMSE_Test,\n",
    "        'STD_Test':std_test,\n",
    "        'R2_Test':R2_Test \n",
    "        }\n",
    "\n",
    "      res = res.append(new_row,ignore_index=True)\n",
    "      ################################################################################################################################################     \n",
    "\n",
    "      # Index for the next target y\n",
    "      idx+=1\n",
    "\n",
    "\n",
    "res.to_excel(\"../../../res.xlsx\",index=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ace568d36d830c5571f2829ec101ed577db7d1f44057a629faa8733711eb527"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

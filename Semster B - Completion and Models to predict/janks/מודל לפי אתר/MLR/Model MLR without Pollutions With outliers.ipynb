{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"import pandas as pd\\nimport dtale\\nimport numpy as np\\nfrom sklearn.preprocessing import PolynomialFeatures\\nimport plotly.graph_objects as go # for visualization\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn import metrics\\nimport os\\nimport statsmodels.api as sm\\n\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\n%load_ext nb_black\\n%load_ext blackcellmagic\\n\\npd.set_option('display.max_rows', 1000)\\npd.set_option('display.max_columns', 1000)\\npd.set_option('display.width', 1000)\";\n                var nbb_formatted_code = \"import pandas as pd\\nimport dtale\\nimport numpy as np\\nfrom sklearn.preprocessing import PolynomialFeatures\\nimport plotly.graph_objects as go  # for visualization\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn import metrics\\nimport os\\nimport statsmodels.api as sm\\n\\nimport matplotlib.pyplot as plt\\n\\n%matplotlib inline\\n\\n%load_ext nb_black\\n%load_ext blackcellmagic\\n\\npd.set_option(\\\"display.max_rows\\\", 1000)\\npd.set_option(\\\"display.max_columns\\\", 1000)\\npd.set_option(\\\"display.width\\\", 1000)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dtale\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import plotly.graph_objects as go # for visualization\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext nb_black\n",
    "%load_ext blackcellmagic\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 45;\n                var nbb_unformatted_code = \"df = pd.read_excel(\\\"../../../site_info_ver_3.2.xlsx\\\")\";\n                var nbb_formatted_code = \"df = pd.read_excel(\\\"../../../site_info_ver_3.2.xlsx\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_excel(\"../../../site_info_ver_3.2.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 46;\n                var nbb_unformatted_code = \"df_sites = []\\nsites = df.Site_Name.unique()\\nfor site in sites:\\n    tmp = df[df.Site_Name==site]\\n    tmp.reset_index(drop=True,inplace=True)\\n    df_sites.append(tmp)\";\n                var nbb_formatted_code = \"df_sites = []\\nsites = df.Site_Name.unique()\\nfor site in sites:\\n    tmp = df[df.Site_Name == site]\\n    tmp.reset_index(drop=True, inplace=True)\\n    df_sites.append(tmp)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_sites = []\n",
    "sites = df.Site_Name.unique()\n",
    "for site in sites:\n",
    "    tmp = df[df.Site_Name==site]\n",
    "    tmp.reset_index(drop=True,inplace=True)\n",
    "    df_sites.append(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 47;\n                var nbb_unformatted_code = \"# df.isna().sum()\\n# df=df.dropna()\\n# df.reset_index(inplace=True,drop=True)\\nfor d in df_sites:\\n    d.drop(['pm10','nox','so2','pm2.5',\\\"Site_Name\\\"],axis=1,inplace=True)\\n# len(df[df.isnull().any(axis=1)])/len(df)\";\n                var nbb_formatted_code = \"# df.isna().sum()\\n# df=df.dropna()\\n# df.reset_index(inplace=True,drop=True)\\nfor d in df_sites:\\n    d.drop([\\\"pm10\\\", \\\"nox\\\", \\\"so2\\\", \\\"pm2.5\\\", \\\"Site_Name\\\"], axis=1, inplace=True)\\n# len(df[df.isnull().any(axis=1)])/len(df)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df.isna().sum()\n",
    "# df=df.dropna()\n",
    "# df.reset_index(inplace=True,drop=True)\n",
    "for d in df_sites:\n",
    "    d.drop(['pm10','nox','so2','pm2.5',\"Site_Name\"],axis=1,inplace=True)\n",
    "# len(df[df.isnull().any(axis=1)])/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defiend X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 48;\n                var nbb_unformatted_code = \"X_site = []\\ntargets_site = []\\nfor d in df_sites:\\n    X_site.append(d.drop(['Israelis_Count','Tourists_Count','Total',\\\"Date\\\",\\\"Model_number\\\"],axis=1))\\n    targets_site.append(d[['Israelis_Count','Tourists_Count','Total']])\";\n                var nbb_formatted_code = \"X_site = []\\ntargets_site = []\\nfor d in df_sites:\\n    X_site.append(\\n        d.drop(\\n            [\\\"Israelis_Count\\\", \\\"Tourists_Count\\\", \\\"Total\\\", \\\"Date\\\", \\\"Model_number\\\"],\\n            axis=1,\\n        )\\n    )\\n    targets_site.append(d[[\\\"Israelis_Count\\\", \\\"Tourists_Count\\\", \\\"Total\\\"]])\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_site = []\n",
    "targets_site = []\n",
    "for d in df_sites:\n",
    "    X_site.append(d.drop(['Israelis_Count','Tourists_Count','Total',\"Date\",\"Model_number\"],axis=1))\n",
    "    targets_site.append(d[['Israelis_Count','Tourists_Count','Total']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaleing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 52;\n                var nbb_unformatted_code = \"from sklearn.preprocessing import MinMaxScaler\\nscaled_X_sites=[]\\nscaled_targets_sites=[]\\nfor i in range(len(X_site)):\\n    #scale X\\n    scaler = MinMaxScaler()\\n    scaled_X_sites.append( pd.DataFrame(scaler.fit_transform(X_site[i]), columns=X_site[i].columns))\\n\\n    #scale y\\n    scaled_targets_sites.append( np.log(targets_site[i]+0.01))\";\n                var nbb_formatted_code = \"from sklearn.preprocessing import MinMaxScaler\\n\\nscaled_X_sites = []\\nscaled_targets_sites = []\\nfor i in range(len(X_site)):\\n    # scale X\\n    scaler = MinMaxScaler()\\n    scaled_X_sites.append(\\n        pd.DataFrame(scaler.fit_transform(X_site[i]), columns=X_site[i].columns)\\n    )\\n\\n    # scale y\\n    scaled_targets_sites.append(np.log(targets_site[i] + 0.01))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaled_X_sites=[]\n",
    "scaled_targets_sites=[]\n",
    "for i in range(len(X_site)):\n",
    "    #scale X\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_X_sites.append( pd.DataFrame(scaler.fit_transform(X_site[i]), columns=X_site[i].columns))\n",
    "\n",
    "    #scale y\n",
    "    scaled_targets_sites.append( np.log(targets_site[i]+0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 9;\n                var nbb_unformatted_code = \"# c = ['hsl('+str(h)+',50%'+',50%)' for h in np.linspace(0, 360, len(scaled_targets_sites[0].columns))]\\n# fig = go.Figure()\\n# fig.add_traces(data=[go.Box( \\n#     y=scaled_targets_sites[0].iloc[:, i], \\n#     marker_color=c[i],\\n#     name=scaled_targets_sites[0].columns[i])\\n#     for i in range(len(scaled_targets_sites[0].columns))\\n#     ])\";\n                var nbb_formatted_code = \"# c = ['hsl('+str(h)+',50%'+',50%)' for h in np.linspace(0, 360, len(scaled_targets_sites[0].columns))]\\n# fig = go.Figure()\\n# fig.add_traces(data=[go.Box(\\n#     y=scaled_targets_sites[0].iloc[:, i],\\n#     marker_color=c[i],\\n#     name=scaled_targets_sites[0].columns[i])\\n#     for i in range(len(scaled_targets_sites[0].columns))\\n#     ])\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# c = ['hsl('+str(h)+',50%'+',50%)' for h in np.linspace(0, 360, len(scaled_targets_sites[0].columns))]\n",
    "# fig = go.Figure()\n",
    "# fig.add_traces(data=[go.Box( \n",
    "#     y=scaled_targets_sites[0].iloc[:, i], \n",
    "#     marker_color=c[i],\n",
    "#     name=scaled_targets_sites[0].columns[i])\n",
    "#     for i in range(len(scaled_targets_sites[0].columns))\n",
    "#     ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 10;\n                var nbb_unformatted_code = \"# outliers_I_sites=[]\\n# outliers_To_sites=[]\\n# outliers_Tu_sites=[]\\n\\n# for j in range(len(scaled_targets_sites)):\\n#     plt.cla()\\n#     data=[scaled_targets_sites[j].Israelis_Count,scaled_targets_sites[j].Total,scaled_targets_sites[j].Tourists_Count]\\n#     bp = plt.boxplot(data)\\n#     minimums = [round(item.get_ydata()[0], 4) for item in bp['caps']][::2]\\n#     maximums = [round(item.get_ydata()[0], 4) for item in bp['caps']][1::2]\\n#     outliers_I_sites.append ( scaled_targets_sites[j][(scaled_targets_sites[j].Israelis_Count>maximums[0])  | (scaled_targets_sites[j].Israelis_Count<minimums[0])])\\n#     outliers_To_sites.append (scaled_targets_sites[j][(scaled_targets_sites[j].Tourists_Count>maximums[1]) | (scaled_targets_sites[j].Tourists_Count<minimums[1])])\\n#     outliers_Tu_sites.append (scaled_targets_sites[j][(scaled_targets_sites[j].Tourists_Count>maximums[2]) | (scaled_targets_sites[j].Tourists_Count<minimums[2])])\";\n                var nbb_formatted_code = \"# outliers_I_sites=[]\\n# outliers_To_sites=[]\\n# outliers_Tu_sites=[]\\n\\n# for j in range(len(scaled_targets_sites)):\\n#     plt.cla()\\n#     data=[scaled_targets_sites[j].Israelis_Count,scaled_targets_sites[j].Total,scaled_targets_sites[j].Tourists_Count]\\n#     bp = plt.boxplot(data)\\n#     minimums = [round(item.get_ydata()[0], 4) for item in bp['caps']][::2]\\n#     maximums = [round(item.get_ydata()[0], 4) for item in bp['caps']][1::2]\\n#     outliers_I_sites.append ( scaled_targets_sites[j][(scaled_targets_sites[j].Israelis_Count>maximums[0])  | (scaled_targets_sites[j].Israelis_Count<minimums[0])])\\n#     outliers_To_sites.append (scaled_targets_sites[j][(scaled_targets_sites[j].Tourists_Count>maximums[1]) | (scaled_targets_sites[j].Tourists_Count<minimums[1])])\\n#     outliers_Tu_sites.append (scaled_targets_sites[j][(scaled_targets_sites[j].Tourists_Count>maximums[2]) | (scaled_targets_sites[j].Tourists_Count<minimums[2])])\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# outliers_I_sites=[]\n",
    "# outliers_To_sites=[]\n",
    "# outliers_Tu_sites=[]\n",
    "\n",
    "# for j in range(len(scaled_targets_sites)):\n",
    "#     plt.cla()\n",
    "#     data=[scaled_targets_sites[j].Israelis_Count,scaled_targets_sites[j].Total,scaled_targets_sites[j].Tourists_Count]\n",
    "#     bp = plt.boxplot(data)\n",
    "#     minimums = [round(item.get_ydata()[0], 4) for item in bp['caps']][::2]\n",
    "#     maximums = [round(item.get_ydata()[0], 4) for item in bp['caps']][1::2]\n",
    "#     outliers_I_sites.append ( scaled_targets_sites[j][(scaled_targets_sites[j].Israelis_Count>maximums[0])  | (scaled_targets_sites[j].Israelis_Count<minimums[0])])\n",
    "#     outliers_To_sites.append (scaled_targets_sites[j][(scaled_targets_sites[j].Tourists_Count>maximums[1]) | (scaled_targets_sites[j].Tourists_Count<minimums[1])])\n",
    "#     outliers_Tu_sites.append (scaled_targets_sites[j][(scaled_targets_sites[j].Tourists_Count>maximums[2]) | (scaled_targets_sites[j].Tourists_Count<minimums[2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model MLR with Pollutions droped Null rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexander Stream-Bet Yannai\n",
      "Apollonia\n",
      "Arbel\n",
      "Avdat\n",
      "Ayun Stream\n",
      "Bet Alpha\n",
      "Bet Guvrin\n",
      "Bet Shean\n",
      "Bet Shearim\n",
      "Caesarea\n",
      "Eilat Coral Beach\n",
      "En Afek\n",
      "En Avdat\n",
      "En Gedi\n",
      "En Prat\n",
      "Enot Tsukim\n",
      "Gamla\n",
      "Good Samaritan Museum\n",
      "Hai Ramon\n",
      "Hamat Tiberias\n",
      "Hay-Bar Yotvata\n",
      "Hermon Stream (Banias)\n",
      "Herodium Park\n",
      "Hula\n",
      "Khan Be’erot\n",
      "Kokhav HaYarden\n",
      "Korazim\n",
      "Kursi\n",
      "Maayan Harod\n",
      "Makhtesh Ramon\n",
      "Mamshit\n",
      "Me‘arot Stream\n",
      "Mount Gerizim\n",
      "Qumran Park\n",
      "Stalactite Cave\n",
      "Tel Arad\n",
      "Tel Beer Sheva\n",
      "Tel Dan\n",
      "Tel Hazor\n",
      "Tel Megiddo\n",
      "The Masada\n",
      "Tzipori\n",
      "Yehiam\n",
      "Amud Stream\n",
      "Ashkelon National Park\n",
      "Baram\n",
      "Dor HaBonim Beach\n",
      "HaBsor(Eshkol Park)\n",
      "Meshushim Stream\n",
      "Palmahim Beach\n",
      "Snir Stream\n",
      "Taninim Stream\n",
      "Castel National site\n",
      "En Hemed\n",
      "Yehudiya\n",
      "The Majrase – Betiha\n",
      "Horshat Tal\n",
      "Nimrod Fortress\n",
      "Akhziv\n",
      "Prat Stream-En Mabo‘a\n",
      "Gan HaShlosha\n",
      "Baptismal Site Qasr al-Yahud\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 67;\n                var nbb_unformatted_code = \"Model_type= \\\"MLR\\\"\\nres=pd.read_excel(\\\"../../../res.xlsx\\\")\\n\\n\\nfor j in range(len(scaled_X_sites)):\\n  Descripton = \\\"Without Pollutions Without outliers for each site \\\" + sites[j]\\n  print(sites[j])\\n  targets = [scaled_targets_sites[j].Israelis_Count,scaled_targets_sites[j].Total,scaled_targets_sites[j].Tourists_Count] # get target info of this site\\n  targets_list_name = ['Israelis_Count','Total','Tourists_Count']\\n  idx=0\\n  for y in targets:\\n\\n      #split the data, train the model and get prediction for the training and for the test  \\n      #######################################################################################################################\\n      X=scaled_X_sites[j] # get X info of this site\\n      # # for outliers \\n      # if idx==0:\\n      #   X=X.drop(outliers_I_sites[j].index)\\n      #   y.drop(outliers_I_sites[j].index,inplace=True)\\n      # elif idx==1:\\n      #   X=X.drop(outliers_To_sites[j].index)\\n      #   y.drop(outliers_To_sites[j].index,inplace=True)\\n      # else :\\n      #   X=X.drop(outliers_Tu_sites[j].index)\\n      #   y.drop(outliers_Tu_sites[j].index,inplace=True)\\n\\n      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=312148513)\\n      train_df_scaled = pd.merge(left=X_train, right=y_train, left_index=True, right_index=True)\\n      test_df_scaled = pd.merge(left=X_test, right=y_test, left_index=True, right_index=True)\\n\\n      lm = LinearRegression()  # define our model using least square method\\n      lm.fit(X_train,y_train)   # Fit our linear model\\n\\n      #train\\n      fitted = np.exp(lm.predict(X_train))\\n      predicted_train = round(pd.Series(fitted, index=y_train.index, name='Predicted_train_'+targets_list_name[idx]),ndigits=2)\\n      orignal_train=np.exp(train_df_scaled[[targets_list_name[idx]]])\\n      train_df = pd.merge(left=orignal_train, right=predicted_train, left_index=True, right_index=True)\\n      train_df\\n\\n      #test\\n      fitted = np.exp(lm.predict(X_test))\\n      predicted_test = round(pd.Series(fitted, index=y_test.index, name='Predicted_test_'+targets_list_name[idx]),ndigits=2)\\n      orignal_test = np.exp(test_df_scaled[[targets_list_name[idx]]])\\n      test_df = pd.merge(left=orignal_test, right=predicted_test, left_index=True, right_index=True)\\n      test_df\\n       #######################################################################################################################\\n\\n\\n\\n\\n\\n       #plot the residuals graph\\n       #######################################################################################################################\\n\\n       #calculate the residuals\\n      test_df['residuals'] = test_df['Predicted_test_'+targets_list_name[idx]] - test_df[targets_list_name[idx]]\\n      train_df['residuals'] = train_df['Predicted_train_'+targets_list_name[idx]] - train_df[targets_list_name[idx]]\\n\\n      fig= go.Figure()\\n      fig.add_trace(\\n        go.Scatter(\\n            x=train_df['Predicted_train_'+targets_list_name[idx]],\\n            y=train_df.residuals,\\n            mode='markers',\\n            name='train residuals',\\n            marker_color='blue',\\n            marker_size=1.5,\\n            marker_line_width=0,\\n         )\\n       )\\n      fig.add_trace(\\n        go.Scatter(\\n            x=test_df['Predicted_test_'+targets_list_name[idx]],\\n            y=test_df.residuals,\\n            mode='markers',\\n            name='test residuals',\\n            marker_color='red',\\n            marker_size=1.5,\\n            marker_line_width=0,\\n         )\\n       )\\n      fig.add_trace(\\n         go.Scatter(\\n            x=test_df['Predicted_test_'+targets_list_name[idx]],\\n            y=test_df.residuals*0,\\n            mode='lines',\\n            name='zero line',\\n            marker_color='black',\\n            marker_size=1.5,\\n            marker_line_width=0,\\n         )\\n       )\\n      fig.update_layout(\\n          title=\\\"Residuals of Predicted \\\"+targets_list_name[idx],\\n          xaxis_title=\\\"Predicted \\\"+targets_list_name[idx],\\n          yaxis_title=\\\"Residuals\\\",\\n          font=dict(\\n              size=14,\\n              color=\\\"RebeccaPurple\\\"\\n          )\\n      )\\n      # fig.show()\\n       #######################################################################################################################\\n\\n       #create folder\\n       ########################################\\n      if not os.path.exists(sites[j]):\\n        os.mkdir(sites[j])\\n\\n      if not os.path.exists(sites[j]+'/'+Descripton):\\n        os.mkdir(sites[j]+'/'+Descripton)\\n      fig.write_image(sites[j]+'/'+Descripton+\\\"/results_\\\"+targets_list_name[idx]+'_.png', width=1500, height=600)\\n      #########################################\\n\\n      #create txt file with the metrix result \\n      ################################################################################################################################################     \\n      f = open(sites[j]+'/'+Descripton+\\\"/results_\\\"+targets_list_name[idx]+'_.txt', 'w')\\n\\n      #  correct_rows = train_df.loc[abs(train_df['Predicted_train_'+targets_list_name[idx]]-train_df[targets_list_name[idx]])<=50].any(axis=1).count()\\n      #  ACC_Training = round(correct_rows/len(train_df),3)\\n\\n      if len(test_df.loc[test_df['Predicted_test_'+targets_list_name[idx]]>=np.infty])/len(test_df)*100 <1:\\n          test_df.drop(test_df.loc[test_df['Predicted_test_'+targets_list_name[idx]]>=np.infty].index,inplace=True)\\n      MSE_Training = metrics.mean_squared_error(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]])\\n      RMSE_Training = np.sqrt(metrics.mean_squared_error(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]]))\\n      MAE_Training = metrics.mean_absolute_error(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]])\\n      R2_Training=metrics.r2_score(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]])\\n      std_Training = np.std(predicted_train)\\n\\n      f.write(\\\"------ TRAIN DATA ------\\\\n\\\")\\n      #f.write(\\\"Model \\\"+' mod0' +\\\" Accuracy: \\\"+str(ACC_Training)+\\\"\\\\n\\\")\\n      f.write(\\\"MSE : \\\"+str(MSE_Training)+\\\", RMSE: \\\"+str(RMSE_Training)+\\\", MAE : \\\"+str(MAE_Training)+\\\"\\\\n\\\")\\n      f.write(\\\"R2 TRAIN \\\"+ str(R2_Training)+\\\"\\\\n\\\")\\n\\n\\n      #  correct_rows = test_df.loc[abs(test_df['Predicted_test_'+targets_list_name[idx]]-test_df[targets_list_name[idx]])<=50].any(axis=1).count()\\n      #  ACC_Test = round(correct_rows/len(test_df),3)\\n\\n      MSE_Test = metrics.mean_squared_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\\n      RMSE_Test = np.sqrt(metrics.mean_squared_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]]))\\n      MAE_Test = metrics.mean_absolute_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\\n      R2_Test = metrics.r2_score(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\\n      std_test = np.std(predicted_test)\\n\\n      f.write(\\\"\\\\n\\\")\\n      f.write(\\\"------ TEST DATA ------\\\\n\\\")\\n      #f.write(\\\"Model \\\"+' mod0' +\\\" Accuracy: \\\"+str(ACC_Test)+\\\"\\\\n\\\")\\n      f.write(\\\"MSE : \\\"+str(MSE_Test)+\\\", RMSE: \\\"+str(RMSE_Test)+\\\", MAE : \\\"+str(MAE_Test)+\\\"\\\\n\\\")\\n      f.write(\\\"R2 TEST \\\"+ str(R2_Test)+\\\"\\\\n\\\")\\n      f.write(\\\"--------------------------------\\\\n\\\")\\n\\n      f.close()\\n      ################################################################################################################################################     \\n\\n      #Add to excel result the new line\\n      ################################################################################################################################################\\n      Target=targets_list_name[idx]\\n      Site_in_this_model=sites[j]\\n      new_row = {\\n        'Descripton':Descripton,\\n        \\\"Target\\\":Target,\\n        'Model_type':Model_type,\\n        # 'Model_number':Model_number,\\n        'Site_in_this_model':Site_in_this_model,\\n        \\\"Size Train\\\":len(train_df),\\n        # 'ACC_Training':ACC_Training,\\n        'MAE_Training':MAE_Training,\\n        'MSE_Training':MSE_Training,\\n        'RMSE_Training':RMSE_Training,\\n        'STD_Training':std_Training,\\n        'R2_Training':R2_Training,\\n        \\\"Size Test\\\":len(test_df),\\n        # 'ACC_Test':ACC_Test,\\n        'MAE_Test':MAE_Test,\\n        'MSE_Test':MSE_Test,\\n        'RMSE_Test':RMSE_Test,\\n        'STD_Test':std_test,\\n        'R2_Test':R2_Test \\n        }\\n\\n      res = res.append(new_row,ignore_index=True)\\n      ################################################################################################################################################     \\n\\n      # Index for the next target y\\n      idx+=1\\n\\n\\nres.to_excel(\\\"../../../res.xlsx\\\",index=False)\";\n                var nbb_formatted_code = \"Model_type = \\\"MLR\\\"\\nres = pd.read_excel(\\\"../../../res.xlsx\\\")\\n\\n\\nfor j in range(len(scaled_X_sites)):\\n    Descripton = \\\"Without Pollutions Without outliers for each site \\\" + sites[j]\\n    print(sites[j])\\n    targets = [\\n        scaled_targets_sites[j].Israelis_Count,\\n        scaled_targets_sites[j].Total,\\n        scaled_targets_sites[j].Tourists_Count,\\n    ]  # get target info of this site\\n    targets_list_name = [\\\"Israelis_Count\\\", \\\"Total\\\", \\\"Tourists_Count\\\"]\\n    idx = 0\\n    for y in targets:\\n\\n        # split the data, train the model and get prediction for the training and for the test\\n        #######################################################################################################################\\n        X = scaled_X_sites[j]  # get X info of this site\\n        # # for outliers\\n        # if idx==0:\\n        #   X=X.drop(outliers_I_sites[j].index)\\n        #   y.drop(outliers_I_sites[j].index,inplace=True)\\n        # elif idx==1:\\n        #   X=X.drop(outliers_To_sites[j].index)\\n        #   y.drop(outliers_To_sites[j].index,inplace=True)\\n        # else :\\n        #   X=X.drop(outliers_Tu_sites[j].index)\\n        #   y.drop(outliers_Tu_sites[j].index,inplace=True)\\n\\n        X_train, X_test, y_train, y_test = train_test_split(\\n            X, y, test_size=0.3, random_state=312148513\\n        )\\n        train_df_scaled = pd.merge(\\n            left=X_train, right=y_train, left_index=True, right_index=True\\n        )\\n        test_df_scaled = pd.merge(\\n            left=X_test, right=y_test, left_index=True, right_index=True\\n        )\\n\\n        lm = LinearRegression()  # define our model using least square method\\n        lm.fit(X_train, y_train)  # Fit our linear model\\n\\n        # train\\n        fitted = np.exp(lm.predict(X_train))\\n        predicted_train = round(\\n            pd.Series(\\n                fitted,\\n                index=y_train.index,\\n                name=\\\"Predicted_train_\\\" + targets_list_name[idx],\\n            ),\\n            ndigits=2,\\n        )\\n        orignal_train = np.exp(train_df_scaled[[targets_list_name[idx]]])\\n        train_df = pd.merge(\\n            left=orignal_train, right=predicted_train, left_index=True, right_index=True\\n        )\\n        train_df\\n\\n        # test\\n        fitted = np.exp(lm.predict(X_test))\\n        predicted_test = round(\\n            pd.Series(\\n                fitted,\\n                index=y_test.index,\\n                name=\\\"Predicted_test_\\\" + targets_list_name[idx],\\n            ),\\n            ndigits=2,\\n        )\\n        orignal_test = np.exp(test_df_scaled[[targets_list_name[idx]]])\\n        test_df = pd.merge(\\n            left=orignal_test, right=predicted_test, left_index=True, right_index=True\\n        )\\n        test_df\\n        #######################################################################################################################\\n\\n        # plot the residuals graph\\n        #######################################################################################################################\\n\\n        # calculate the residuals\\n        test_df[\\\"residuals\\\"] = (\\n            test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]]\\n            - test_df[targets_list_name[idx]]\\n        )\\n        train_df[\\\"residuals\\\"] = (\\n            train_df[\\\"Predicted_train_\\\" + targets_list_name[idx]]\\n            - train_df[targets_list_name[idx]]\\n        )\\n\\n        fig = go.Figure()\\n        fig.add_trace(\\n            go.Scatter(\\n                x=train_df[\\\"Predicted_train_\\\" + targets_list_name[idx]],\\n                y=train_df.residuals,\\n                mode=\\\"markers\\\",\\n                name=\\\"train residuals\\\",\\n                marker_color=\\\"blue\\\",\\n                marker_size=1.5,\\n                marker_line_width=0,\\n            )\\n        )\\n        fig.add_trace(\\n            go.Scatter(\\n                x=test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]],\\n                y=test_df.residuals,\\n                mode=\\\"markers\\\",\\n                name=\\\"test residuals\\\",\\n                marker_color=\\\"red\\\",\\n                marker_size=1.5,\\n                marker_line_width=0,\\n            )\\n        )\\n        fig.add_trace(\\n            go.Scatter(\\n                x=test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]],\\n                y=test_df.residuals * 0,\\n                mode=\\\"lines\\\",\\n                name=\\\"zero line\\\",\\n                marker_color=\\\"black\\\",\\n                marker_size=1.5,\\n                marker_line_width=0,\\n            )\\n        )\\n        fig.update_layout(\\n            title=\\\"Residuals of Predicted \\\" + targets_list_name[idx],\\n            xaxis_title=\\\"Predicted \\\" + targets_list_name[idx],\\n            yaxis_title=\\\"Residuals\\\",\\n            font=dict(size=14, color=\\\"RebeccaPurple\\\"),\\n        )\\n        # fig.show()\\n        #######################################################################################################################\\n\\n        # create folder\\n        ########################################\\n        if not os.path.exists(sites[j]):\\n            os.mkdir(sites[j])\\n\\n        if not os.path.exists(sites[j] + \\\"/\\\" + Descripton):\\n            os.mkdir(sites[j] + \\\"/\\\" + Descripton)\\n        fig.write_image(\\n            sites[j]\\n            + \\\"/\\\"\\n            + Descripton\\n            + \\\"/results_\\\"\\n            + targets_list_name[idx]\\n            + \\\"_.png\\\",\\n            width=1500,\\n            height=600,\\n        )\\n        #########################################\\n\\n        # create txt file with the metrix result\\n        ################################################################################################################################################\\n        f = open(\\n            sites[j]\\n            + \\\"/\\\"\\n            + Descripton\\n            + \\\"/results_\\\"\\n            + targets_list_name[idx]\\n            + \\\"_.txt\\\",\\n            \\\"w\\\",\\n        )\\n\\n        #  correct_rows = train_df.loc[abs(train_df['Predicted_train_'+targets_list_name[idx]]-train_df[targets_list_name[idx]])<=50].any(axis=1).count()\\n        #  ACC_Training = round(correct_rows/len(train_df),3)\\n\\n        if (\\n            len(\\n                test_df.loc[\\n                    test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]] >= np.infty\\n                ]\\n            )\\n            / len(test_df)\\n            * 100\\n            < 1\\n        ):\\n            test_df.drop(\\n                test_df.loc[\\n                    test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]] >= np.infty\\n                ].index,\\n                inplace=True,\\n            )\\n        MSE_Training = metrics.mean_squared_error(\\n            train_df[targets_list_name[idx]],\\n            train_df[\\\"Predicted_train_\\\" + targets_list_name[idx]],\\n        )\\n        RMSE_Training = np.sqrt(\\n            metrics.mean_squared_error(\\n                train_df[targets_list_name[idx]],\\n                train_df[\\\"Predicted_train_\\\" + targets_list_name[idx]],\\n            )\\n        )\\n        MAE_Training = metrics.mean_absolute_error(\\n            train_df[targets_list_name[idx]],\\n            train_df[\\\"Predicted_train_\\\" + targets_list_name[idx]],\\n        )\\n        R2_Training = metrics.r2_score(\\n            train_df[targets_list_name[idx]],\\n            train_df[\\\"Predicted_train_\\\" + targets_list_name[idx]],\\n        )\\n        std_Training = np.std(predicted_train)\\n\\n        f.write(\\\"------ TRAIN DATA ------\\\\n\\\")\\n        # f.write(\\\"Model \\\"+' mod0' +\\\" Accuracy: \\\"+str(ACC_Training)+\\\"\\\\n\\\")\\n        f.write(\\n            \\\"MSE : \\\"\\n            + str(MSE_Training)\\n            + \\\", RMSE: \\\"\\n            + str(RMSE_Training)\\n            + \\\", MAE : \\\"\\n            + str(MAE_Training)\\n            + \\\"\\\\n\\\"\\n        )\\n        f.write(\\\"R2 TRAIN \\\" + str(R2_Training) + \\\"\\\\n\\\")\\n\\n        #  correct_rows = test_df.loc[abs(test_df['Predicted_test_'+targets_list_name[idx]]-test_df[targets_list_name[idx]])<=50].any(axis=1).count()\\n        #  ACC_Test = round(correct_rows/len(test_df),3)\\n\\n        MSE_Test = metrics.mean_squared_error(\\n            test_df[targets_list_name[idx]],\\n            test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]],\\n        )\\n        RMSE_Test = np.sqrt(\\n            metrics.mean_squared_error(\\n                test_df[targets_list_name[idx]],\\n                test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]],\\n            )\\n        )\\n        MAE_Test = metrics.mean_absolute_error(\\n            test_df[targets_list_name[idx]],\\n            test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]],\\n        )\\n        R2_Test = metrics.r2_score(\\n            test_df[targets_list_name[idx]],\\n            test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]],\\n        )\\n        std_test = np.std(predicted_test)\\n\\n        f.write(\\\"\\\\n\\\")\\n        f.write(\\\"------ TEST DATA ------\\\\n\\\")\\n        # f.write(\\\"Model \\\"+' mod0' +\\\" Accuracy: \\\"+str(ACC_Test)+\\\"\\\\n\\\")\\n        f.write(\\n            \\\"MSE : \\\"\\n            + str(MSE_Test)\\n            + \\\", RMSE: \\\"\\n            + str(RMSE_Test)\\n            + \\\", MAE : \\\"\\n            + str(MAE_Test)\\n            + \\\"\\\\n\\\"\\n        )\\n        f.write(\\\"R2 TEST \\\" + str(R2_Test) + \\\"\\\\n\\\")\\n        f.write(\\\"--------------------------------\\\\n\\\")\\n\\n        f.close()\\n        ################################################################################################################################################\\n\\n        # Add to excel result the new line\\n        ################################################################################################################################################\\n        Target = targets_list_name[idx]\\n        Site_in_this_model = sites[j]\\n        new_row = {\\n            \\\"Descripton\\\": Descripton,\\n            \\\"Target\\\": Target,\\n            \\\"Model_type\\\": Model_type,\\n            # 'Model_number':Model_number,\\n            \\\"Site_in_this_model\\\": Site_in_this_model,\\n            \\\"Size Train\\\": len(train_df),\\n            # 'ACC_Training':ACC_Training,\\n            \\\"MAE_Training\\\": MAE_Training,\\n            \\\"MSE_Training\\\": MSE_Training,\\n            \\\"RMSE_Training\\\": RMSE_Training,\\n            \\\"STD_Training\\\": std_Training,\\n            \\\"R2_Training\\\": R2_Training,\\n            \\\"Size Test\\\": len(test_df),\\n            # 'ACC_Test':ACC_Test,\\n            \\\"MAE_Test\\\": MAE_Test,\\n            \\\"MSE_Test\\\": MSE_Test,\\n            \\\"RMSE_Test\\\": RMSE_Test,\\n            \\\"STD_Test\\\": std_test,\\n            \\\"R2_Test\\\": R2_Test,\\n        }\\n\\n        res = res.append(new_row, ignore_index=True)\\n        ################################################################################################################################################\\n\\n        # Index for the next target y\\n        idx += 1\\n\\n\\nres.to_excel(\\\"../../../res.xlsx\\\", index=False)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Model_type= \"MLR\"\n",
    "res=pd.read_excel(\"../../../res.xlsx\")\n",
    "\n",
    "\n",
    "for j in range(len(scaled_X_sites)):\n",
    "  Descripton = \"Without Pollutions Without outliers for each site \" + sites[j]\n",
    "  print(sites[j])\n",
    "  targets = [scaled_targets_sites[j].Israelis_Count,scaled_targets_sites[j].Total,scaled_targets_sites[j].Tourists_Count] # get target info of this site\n",
    "  targets_list_name = ['Israelis_Count','Total','Tourists_Count']\n",
    "  idx=0\n",
    "  for y in targets:\n",
    "\n",
    "      #split the data, train the model and get prediction for the training and for the test  \n",
    "      #######################################################################################################################\n",
    "      X=scaled_X_sites[j] # get X info of this site\n",
    "      # # for outliers \n",
    "      # if idx==0:\n",
    "      #   X=X.drop(outliers_I_sites[j].index)\n",
    "      #   y.drop(outliers_I_sites[j].index,inplace=True)\n",
    "      # elif idx==1:\n",
    "      #   X=X.drop(outliers_To_sites[j].index)\n",
    "      #   y.drop(outliers_To_sites[j].index,inplace=True)\n",
    "      # else :\n",
    "      #   X=X.drop(outliers_Tu_sites[j].index)\n",
    "      #   y.drop(outliers_Tu_sites[j].index,inplace=True)\n",
    "\n",
    "      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=312148513)\n",
    "      train_df_scaled = pd.merge(left=X_train, right=y_train, left_index=True, right_index=True)\n",
    "      test_df_scaled = pd.merge(left=X_test, right=y_test, left_index=True, right_index=True)\n",
    "\n",
    "      lm = LinearRegression()  # define our model using least square method\n",
    "      lm.fit(X_train,y_train)   # Fit our linear model\n",
    "\n",
    "      #train\n",
    "      fitted = np.exp(lm.predict(X_train))\n",
    "      predicted_train = round(pd.Series(fitted, index=y_train.index, name='Predicted_train_'+targets_list_name[idx]),ndigits=2)\n",
    "      orignal_train=np.exp(train_df_scaled[[targets_list_name[idx]]])\n",
    "      train_df = pd.merge(left=orignal_train, right=predicted_train, left_index=True, right_index=True)\n",
    "      train_df\n",
    "\n",
    "      #test\n",
    "      fitted = np.exp(lm.predict(X_test))\n",
    "      predicted_test = round(pd.Series(fitted, index=y_test.index, name='Predicted_test_'+targets_list_name[idx]),ndigits=2)\n",
    "      orignal_test = np.exp(test_df_scaled[[targets_list_name[idx]]])\n",
    "      test_df = pd.merge(left=orignal_test, right=predicted_test, left_index=True, right_index=True)\n",
    "      test_df\n",
    "       #######################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "       #plot the residuals graph\n",
    "       #######################################################################################################################\n",
    "\n",
    "       #calculate the residuals\n",
    "      test_df['residuals'] = test_df['Predicted_test_'+targets_list_name[idx]] - test_df[targets_list_name[idx]]\n",
    "      train_df['residuals'] = train_df['Predicted_train_'+targets_list_name[idx]] - train_df[targets_list_name[idx]]\n",
    "\n",
    "      fig= go.Figure()\n",
    "      fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=train_df['Predicted_train_'+targets_list_name[idx]],\n",
    "            y=train_df.residuals,\n",
    "            mode='markers',\n",
    "            name='train residuals',\n",
    "            marker_color='blue',\n",
    "            marker_size=1.5,\n",
    "            marker_line_width=0,\n",
    "         )\n",
    "       )\n",
    "      fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=test_df['Predicted_test_'+targets_list_name[idx]],\n",
    "            y=test_df.residuals,\n",
    "            mode='markers',\n",
    "            name='test residuals',\n",
    "            marker_color='red',\n",
    "            marker_size=1.5,\n",
    "            marker_line_width=0,\n",
    "         )\n",
    "       )\n",
    "      fig.add_trace(\n",
    "         go.Scatter(\n",
    "            x=test_df['Predicted_test_'+targets_list_name[idx]],\n",
    "            y=test_df.residuals*0,\n",
    "            mode='lines',\n",
    "            name='zero line',\n",
    "            marker_color='black',\n",
    "            marker_size=1.5,\n",
    "            marker_line_width=0,\n",
    "         )\n",
    "       )\n",
    "      fig.update_layout(\n",
    "          title=\"Residuals of Predicted \"+targets_list_name[idx],\n",
    "          xaxis_title=\"Predicted \"+targets_list_name[idx],\n",
    "          yaxis_title=\"Residuals\",\n",
    "          font=dict(\n",
    "              size=14,\n",
    "              color=\"RebeccaPurple\"\n",
    "          )\n",
    "      )\n",
    "      # fig.show()\n",
    "       #######################################################################################################################\n",
    "\n",
    "       #create folder\n",
    "       ########################################\n",
    "      if not os.path.exists(sites[j]):\n",
    "        os.mkdir(sites[j])\n",
    "\n",
    "      if not os.path.exists(sites[j]+'/'+Descripton):\n",
    "        os.mkdir(sites[j]+'/'+Descripton)\n",
    "      fig.write_image(sites[j]+'/'+Descripton+\"/results_\"+targets_list_name[idx]+'_.png', width=1500, height=600)\n",
    "      #########################################\n",
    "\n",
    "      #create txt file with the metrix result \n",
    "      ################################################################################################################################################     \n",
    "      f = open(sites[j]+'/'+Descripton+\"/results_\"+targets_list_name[idx]+'_.txt', 'w')\n",
    "\n",
    "      #  correct_rows = train_df.loc[abs(train_df['Predicted_train_'+targets_list_name[idx]]-train_df[targets_list_name[idx]])<=50].any(axis=1).count()\n",
    "      #  ACC_Training = round(correct_rows/len(train_df),3)\n",
    "\n",
    "      if len(test_df.loc[test_df['Predicted_test_'+targets_list_name[idx]]>=np.infty])/len(test_df)*100 <1:\n",
    "          test_df.drop(test_df.loc[test_df['Predicted_test_'+targets_list_name[idx]]>=np.infty].index,inplace=True)\n",
    "      MSE_Training = metrics.mean_squared_error(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]])\n",
    "      RMSE_Training = np.sqrt(metrics.mean_squared_error(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]]))\n",
    "      MAE_Training = metrics.mean_absolute_error(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]])\n",
    "      R2_Training=metrics.r2_score(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]])\n",
    "      std_Training = np.std(predicted_train)\n",
    "\n",
    "      f.write(\"------ TRAIN DATA ------\\n\")\n",
    "      #f.write(\"Model \"+' mod0' +\" Accuracy: \"+str(ACC_Training)+\"\\n\")\n",
    "      f.write(\"MSE : \"+str(MSE_Training)+\", RMSE: \"+str(RMSE_Training)+\", MAE : \"+str(MAE_Training)+\"\\n\")\n",
    "      f.write(\"R2 TRAIN \"+ str(R2_Training)+\"\\n\")\n",
    "\n",
    "\n",
    "      #  correct_rows = test_df.loc[abs(test_df['Predicted_test_'+targets_list_name[idx]]-test_df[targets_list_name[idx]])<=50].any(axis=1).count()\n",
    "      #  ACC_Test = round(correct_rows/len(test_df),3)\n",
    "\n",
    "      MSE_Test = metrics.mean_squared_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\n",
    "      RMSE_Test = np.sqrt(metrics.mean_squared_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]]))\n",
    "      MAE_Test = metrics.mean_absolute_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\n",
    "      R2_Test = metrics.r2_score(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\n",
    "      std_test = np.std(predicted_test)\n",
    "\n",
    "      f.write(\"\\n\")\n",
    "      f.write(\"------ TEST DATA ------\\n\")\n",
    "      #f.write(\"Model \"+' mod0' +\" Accuracy: \"+str(ACC_Test)+\"\\n\")\n",
    "      f.write(\"MSE : \"+str(MSE_Test)+\", RMSE: \"+str(RMSE_Test)+\", MAE : \"+str(MAE_Test)+\"\\n\")\n",
    "      f.write(\"R2 TEST \"+ str(R2_Test)+\"\\n\")\n",
    "      f.write(\"--------------------------------\\n\")\n",
    "\n",
    "      f.close()\n",
    "      ################################################################################################################################################     \n",
    "\n",
    "      #Add to excel result the new line\n",
    "      ################################################################################################################################################\n",
    "      Target=targets_list_name[idx]\n",
    "      Site_in_this_model=sites[j]\n",
    "      new_row = {\n",
    "        'Descripton':Descripton,\n",
    "        \"Target\":Target,\n",
    "        'Model_type':Model_type,\n",
    "        # 'Model_number':Model_number,\n",
    "        'Site_in_this_model':Site_in_this_model,\n",
    "        \"Size Train\":len(train_df),\n",
    "        # 'ACC_Training':ACC_Training,\n",
    "        'MAE_Training':MAE_Training,\n",
    "        'MSE_Training':MSE_Training,\n",
    "        'RMSE_Training':RMSE_Training,\n",
    "        'STD_Training':std_Training,\n",
    "        'R2_Training':R2_Training,\n",
    "        \"Size Test\":len(test_df),\n",
    "        # 'ACC_Test':ACC_Test,\n",
    "        'MAE_Test':MAE_Test,\n",
    "        'MSE_Test':MSE_Test,\n",
    "        'RMSE_Test':RMSE_Test,\n",
    "        'STD_Test':std_test,\n",
    "        'R2_Test':R2_Test \n",
    "        }\n",
    "\n",
    "      res = res.append(new_row,ignore_index=True)\n",
    "      ################################################################################################################################################     \n",
    "\n",
    "      # Index for the next target y\n",
    "      idx+=1\n",
    "\n",
    "\n",
    "res.to_excel(\"../../../res.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 64;\n                var nbb_unformatted_code = \"# MSE_Test = metrics.mean_squared_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\\nimport math\\n\\nif len(test_df.loc[test_df['Predicted_test_'+targets_list_name[idx]]>=np.infty])/len(test_df)*100 <1:\\n          test_df.drop(test_df.loc[test_df['Predicted_test_'+targets_list_name[idx]]>=np.infty].index)\";\n                var nbb_formatted_code = \"# MSE_Test = metrics.mean_squared_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\\nimport math\\n\\nif (\\n    len(test_df.loc[test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]] >= np.infty])\\n    / len(test_df)\\n    * 100\\n    < 1\\n):\\n    test_df.drop(\\n        test_df.loc[\\n            test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]] >= np.infty\\n        ].index\\n    )\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MSE_Test = metrics.mean_squared_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\n",
    "\n",
    "if len(test_df.loc[test_df['Predicted_test_'+targets_list_name[idx]]>=np.infty])/len(test_df)*100 <1:\n",
    "          test_df.drop(test_df.loc[test_df['Predicted_test_'+targets_list_name[idx]]>=np.infty].index)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ace568d36d830c5571f2829ec101ed577db7d1f44057a629faa8733711eb527"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

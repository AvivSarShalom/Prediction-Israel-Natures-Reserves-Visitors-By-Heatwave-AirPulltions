{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"import pandas as pd\\nimport dtale\\nimport numpy as np\\nfrom sklearn.preprocessing import PolynomialFeatures\\nimport plotly.graph_objects as go # for visualization\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn import metrics\\nimport os\\nimport statsmodels.api as sm\\n\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\n%load_ext nb_black\\n%load_ext blackcellmagic\\n\\npd.set_option('display.max_rows', 1000)\\npd.set_option('display.max_columns', 1000)\\npd.set_option('display.width', 1000)\";\n                var nbb_formatted_code = \"import pandas as pd\\nimport dtale\\nimport numpy as np\\nfrom sklearn.preprocessing import PolynomialFeatures\\nimport plotly.graph_objects as go  # for visualization\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn import metrics\\nimport os\\nimport statsmodels.api as sm\\n\\nimport matplotlib.pyplot as plt\\n\\n%matplotlib inline\\n\\n%load_ext nb_black\\n%load_ext blackcellmagic\\n\\npd.set_option(\\\"display.max_rows\\\", 1000)\\npd.set_option(\\\"display.max_columns\\\", 1000)\\npd.set_option(\\\"display.width\\\", 1000)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dtale\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import plotly.graph_objects as go # for visualization\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext nb_black\n",
    "%load_ext blackcellmagic\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"df = pd.read_excel(\\\"../../../site_info_ver_3.2.xlsx\\\")\";\n                var nbb_formatted_code = \"df = pd.read_excel(\\\"../../../site_info_ver_3.2.xlsx\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_excel(\"../../../site_info_ver_3.2.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Model_number</th>\n",
       "      <th>Site_Name</th>\n",
       "      <th>Israelis_Count</th>\n",
       "      <th>Tourists_Count</th>\n",
       "      <th>Total</th>\n",
       "      <th>region_Central</th>\n",
       "      <th>region_Judea_Samaria</th>\n",
       "      <th>region_North</th>\n",
       "      <th>region_South</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>operations</th>\n",
       "      <th>is_jewish_holiday</th>\n",
       "      <th>is_jewish_vacation</th>\n",
       "      <th>is_muslims_holiday</th>\n",
       "      <th>is_muslims_vacation</th>\n",
       "      <th>is_camping</th>\n",
       "      <th>special_activity</th>\n",
       "      <th>visit_duration</th>\n",
       "      <th>is_jewishHeritage</th>\n",
       "      <th>is_muslimsHeritage</th>\n",
       "      <th>is_christiansHeritage</th>\n",
       "      <th>is_nationalPark</th>\n",
       "      <th>is_natureReserve</th>\n",
       "      <th>is_archaeology</th>\n",
       "      <th>is_religion</th>\n",
       "      <th>is_animals</th>\n",
       "      <th>is_heritage</th>\n",
       "      <th>is_water</th>\n",
       "      <th>is_cave</th>\n",
       "      <th>is_lookout</th>\n",
       "      <th>pm10</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>nox</th>\n",
       "      <th>so2</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>is_HeatWave</th>\n",
       "      <th>Tel_Aviv-Yafo_pm10</th>\n",
       "      <th>Jerusalem_pm10</th>\n",
       "      <th>Haifa_pm10</th>\n",
       "      <th>Ashkelon_pm10</th>\n",
       "      <th>Beer-Sheva_pm10</th>\n",
       "      <th>Tel_Aviv-Yafo_pm2.5</th>\n",
       "      <th>Jerusalem_pm2.5</th>\n",
       "      <th>Haifa_pm2.5</th>\n",
       "      <th>Ashkelon_pm2.5</th>\n",
       "      <th>Beer-Sheva_pm2.5</th>\n",
       "      <th>Tel_Aviv-Yafo_nox</th>\n",
       "      <th>Jerusalem_nox</th>\n",
       "      <th>Haifa_nox</th>\n",
       "      <th>Ashkelon_nox</th>\n",
       "      <th>Beer-Sheva_nox</th>\n",
       "      <th>Tel_Aviv-Yafo_so2</th>\n",
       "      <th>Jerusalem_so2</th>\n",
       "      <th>Haifa_so2</th>\n",
       "      <th>Ashkelon_so2</th>\n",
       "      <th>Beer-Sheva_so2</th>\n",
       "      <th>is_Site_exceeded_pm10</th>\n",
       "      <th>is_Site_exceeded_pm2.5</th>\n",
       "      <th>is_Site_exceeded_nox</th>\n",
       "      <th>is_Site_exceeded_so2</th>\n",
       "      <th>Tel_Aviv-Yafo_pm10_exceeded</th>\n",
       "      <th>Jerusalem_pm10_exceeded</th>\n",
       "      <th>Haifa_pm10_exceeded</th>\n",
       "      <th>Ashkelon_pm10_exceeded</th>\n",
       "      <th>Beer-Sheva_pm10_exceeded</th>\n",
       "      <th>Tel_Aviv-Yafo_pm2.5_exceeded</th>\n",
       "      <th>Jerusalem_pm2.5_exceeded</th>\n",
       "      <th>Haifa_pm2.5_exceeded</th>\n",
       "      <th>Ashkelon_pm2.5_exceeded</th>\n",
       "      <th>Beer-Sheva_pm2.5_exceeded</th>\n",
       "      <th>Tel_Aviv-Yafo_so2_exceeded</th>\n",
       "      <th>Jerusalem_so2_exceeded</th>\n",
       "      <th>Haifa_so2_exceeded</th>\n",
       "      <th>Ashkelon_so2_exceeded</th>\n",
       "      <th>Beer-Sheva_so2_exceeded</th>\n",
       "      <th>Tel_Aviv-Yafo_nox_exceeded</th>\n",
       "      <th>Jerusalem_nox_exceeded</th>\n",
       "      <th>Haifa_nox_exceeded</th>\n",
       "      <th>Ashkelon_nox_exceeded</th>\n",
       "      <th>Beer-Sheva_nox_exceeded</th>\n",
       "      <th>Green_border</th>\n",
       "      <th>Season_autumn</th>\n",
       "      <th>Season_spring</th>\n",
       "      <th>Season_summer</th>\n",
       "      <th>Season_winter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>Alexander Stream-Bet Yannai</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.20</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0</td>\n",
       "      <td>64.1</td>\n",
       "      <td>25.6</td>\n",
       "      <td>23.3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>13.9</td>\n",
       "      <td>30.1</td>\n",
       "      <td>26.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>69.1</td>\n",
       "      <td>501.7</td>\n",
       "      <td>90.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>5</td>\n",
       "      <td>Alexander Stream-Bet Yannai</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.10</td>\n",
       "      <td>7.5</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0</td>\n",
       "      <td>154.1</td>\n",
       "      <td>277.1</td>\n",
       "      <td>50.6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>51.4</td>\n",
       "      <td>87.1</td>\n",
       "      <td>80.7</td>\n",
       "      <td>93.9</td>\n",
       "      <td>21.6</td>\n",
       "      <td>36.0</td>\n",
       "      <td>749.9</td>\n",
       "      <td>1140.2</td>\n",
       "      <td>842.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>115.7</td>\n",
       "      <td>16.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>5</td>\n",
       "      <td>Alexander Stream-Bet Yannai</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.80</td>\n",
       "      <td>16.1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0</td>\n",
       "      <td>80.8</td>\n",
       "      <td>303.2</td>\n",
       "      <td>82.3</td>\n",
       "      <td>45.3</td>\n",
       "      <td>49.3</td>\n",
       "      <td>44.6</td>\n",
       "      <td>73.6</td>\n",
       "      <td>123.1</td>\n",
       "      <td>27.7</td>\n",
       "      <td>25.5</td>\n",
       "      <td>120.8</td>\n",
       "      <td>1152.4</td>\n",
       "      <td>208.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>37.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-09</td>\n",
       "      <td>5</td>\n",
       "      <td>Alexander Stream-Bet Yannai</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0</td>\n",
       "      <td>90.9</td>\n",
       "      <td>224.5</td>\n",
       "      <td>24.8</td>\n",
       "      <td>23.7</td>\n",
       "      <td>38.8</td>\n",
       "      <td>49.1</td>\n",
       "      <td>63.5</td>\n",
       "      <td>89.8</td>\n",
       "      <td>26.3</td>\n",
       "      <td>20.2</td>\n",
       "      <td>166.9</td>\n",
       "      <td>1268.1</td>\n",
       "      <td>225.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>37.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>5</td>\n",
       "      <td>Alexander Stream-Bet Yannai</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.80</td>\n",
       "      <td>3.9</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0</td>\n",
       "      <td>90.7</td>\n",
       "      <td>105.3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>13.7</td>\n",
       "      <td>20.3</td>\n",
       "      <td>57.1</td>\n",
       "      <td>25.9</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.1</td>\n",
       "      <td>338.0</td>\n",
       "      <td>664.9</td>\n",
       "      <td>451.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>48.3</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31472</th>\n",
       "      <td>2021-07-03</td>\n",
       "      <td>2</td>\n",
       "      <td>Baptismal Site Qasr al-Yahud</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>378.5</td>\n",
       "      <td>57.9</td>\n",
       "      <td>720.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.5</td>\n",
       "      <td>1</td>\n",
       "      <td>133.7</td>\n",
       "      <td>378.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>27.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>162.8</td>\n",
       "      <td>57.9</td>\n",
       "      <td>109.3</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1397.4</td>\n",
       "      <td>720.9</td>\n",
       "      <td>356.5</td>\n",
       "      <td>11.4</td>\n",
       "      <td>40.7</td>\n",
       "      <td>9.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>15.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31473</th>\n",
       "      <td>2021-07-09</td>\n",
       "      <td>2</td>\n",
       "      <td>Baptismal Site Qasr al-Yahud</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.4</td>\n",
       "      <td>38.5</td>\n",
       "      <td>1</td>\n",
       "      <td>121.6</td>\n",
       "      <td>117.9</td>\n",
       "      <td>102.0</td>\n",
       "      <td>29.9</td>\n",
       "      <td>25.6</td>\n",
       "      <td>138.0</td>\n",
       "      <td>47.5</td>\n",
       "      <td>109.6</td>\n",
       "      <td>17.2</td>\n",
       "      <td>11.9</td>\n",
       "      <td>111.7</td>\n",
       "      <td>49.1</td>\n",
       "      <td>60.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>15.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31474</th>\n",
       "      <td>2021-07-10</td>\n",
       "      <td>2</td>\n",
       "      <td>Baptismal Site Qasr al-Yahud</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.8</td>\n",
       "      <td>12.5</td>\n",
       "      <td>26.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.5</td>\n",
       "      <td>1</td>\n",
       "      <td>138.2</td>\n",
       "      <td>431.3</td>\n",
       "      <td>115.1</td>\n",
       "      <td>41.1</td>\n",
       "      <td>40.8</td>\n",
       "      <td>118.9</td>\n",
       "      <td>77.5</td>\n",
       "      <td>110.0</td>\n",
       "      <td>23.8</td>\n",
       "      <td>12.1</td>\n",
       "      <td>1118.4</td>\n",
       "      <td>902.9</td>\n",
       "      <td>415.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>46.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>17.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31475</th>\n",
       "      <td>2021-07-16</td>\n",
       "      <td>2</td>\n",
       "      <td>Baptismal Site Qasr al-Yahud</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>18.9</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.2</td>\n",
       "      <td>38.5</td>\n",
       "      <td>1</td>\n",
       "      <td>174.7</td>\n",
       "      <td>227.3</td>\n",
       "      <td>119.8</td>\n",
       "      <td>45.4</td>\n",
       "      <td>45.3</td>\n",
       "      <td>207.1</td>\n",
       "      <td>108.4</td>\n",
       "      <td>189.4</td>\n",
       "      <td>27.2</td>\n",
       "      <td>19.7</td>\n",
       "      <td>266.8</td>\n",
       "      <td>545.5</td>\n",
       "      <td>81.8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>22.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31476</th>\n",
       "      <td>2021-08-07</td>\n",
       "      <td>2</td>\n",
       "      <td>Baptismal Site Qasr al-Yahud</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>76.9</td>\n",
       "      <td>821.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.5</td>\n",
       "      <td>1</td>\n",
       "      <td>143.3</td>\n",
       "      <td>441.0</td>\n",
       "      <td>105.1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>37.7</td>\n",
       "      <td>185.5</td>\n",
       "      <td>76.9</td>\n",
       "      <td>163.1</td>\n",
       "      <td>18.1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>1219.5</td>\n",
       "      <td>821.8</td>\n",
       "      <td>183.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>13.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31477 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Model_number                     Site_Name  Israelis_Count  Tourists_Count  Total  region_Central  region_Judea_Samaria  region_North  region_South  is_weekend  operations  is_jewish_holiday  is_jewish_vacation  is_muslims_holiday  is_muslims_vacation  is_camping  special_activity  visit_duration  is_jewishHeritage  is_muslimsHeritage  is_christiansHeritage  is_nationalPark  is_natureReserve  is_archaeology  is_religion  is_animals  is_heritage  is_water  is_cave  is_lookout   pm10  pm2.5     nox   so2  Temperature  is_HeatWave  Tel_Aviv-Yafo_pm10  Jerusalem_pm10  Haifa_pm10  Ashkelon_pm10  Beer-Sheva_pm10  Tel_Aviv-Yafo_pm2.5  Jerusalem_pm2.5  Haifa_pm2.5  Ashkelon_pm2.5  Beer-Sheva_pm2.5  Tel_Aviv-Yafo_nox  Jerusalem_nox  Haifa_nox  Ashkelon_nox  Beer-Sheva_nox  Tel_Aviv-Yafo_so2  Jerusalem_so2  Haifa_so2  Ashkelon_so2  Beer-Sheva_so2  is_Site_exceeded_pm10  is_Site_exceeded_pm2.5  is_Site_exceeded_nox  is_Site_exceeded_so2  Tel_Aviv-Yafo_pm10_exceeded  \\\n",
       "0     2016-01-01             5   Alexander Stream-Bet Yannai               7               0      7               1                     0             0             0           1           0                  0                   0                   0                    0           0                 0               3                  0                   0                      0                1                 0               0            0           0            0         1        0           0    8.0    NaN    6.20   0.6         15.5            0                64.1            25.6        23.3           11.2              4.9                 13.9             30.1         26.2             4.8               2.5               69.1          501.7       90.2           3.8             9.7                7.2            0.1        2.6           1.2             0.9                      0                       0                     0                     0                            0   \n",
       "1     2016-01-02             5   Alexander Stream-Bet Yannai              28               0     28               1                     0             0             0           1           0                  0                   0                   0                    0           0                 0               3                  0                   0                      0                1                 0               0            0           0            0         1        0           0   23.5    NaN   66.10   7.5         13.8            0               154.1           277.1        50.6           26.0             51.4                 87.1             80.7         93.9            21.6              36.0              749.9         1140.2      842.8          10.8           115.7               16.7            1.9       20.0           8.8             2.3                      0                       0                     1                     0                            1   \n",
       "2     2016-01-08             5   Alexander Stream-Bet Yannai              14               0     14               1                     0             0             0           1           0                  0                   0                   0                    0           0                 0               3                  0                   0                      0                1                 0               0            0           0            0         1        0           0    NaN    NaN   25.80  16.1         20.5            0                80.8           303.2        82.3           45.3             49.3                 44.6             73.6        123.1            27.7              25.5              120.8         1152.4      208.7           5.4            37.8                8.0            0.2        2.3           0.8             1.5                      0                       0                     0                     0                            0   \n",
       "3     2016-01-09             5   Alexander Stream-Bet Yannai              71               0     71               1                     0             0             0           1           0                  0                   0                   0                    0           0                 0               3                  0                   0                      0                1                 0               0            0           0            0         1        0           0   36.7    NaN   22.97   0.0         18.2            0                90.9           224.5        24.8           23.7             38.8                 49.1             63.5         89.8            26.3              20.2              166.9         1268.1      225.1           2.2            37.1                7.6            0.9        6.3           2.2             2.2                      0                       0                     0                     0                            0   \n",
       "4     2016-01-15             5   Alexander Stream-Bet Yannai              64               0     64               1                     0             0             0           1           0                  0                   0                   0                    0           0                 0               3                  0                   0                      0                1                 0               0            0           0            0         1        0           0    NaN    NaN   57.80   3.9         19.5            0                90.7           105.3        30.0           13.8             13.7                 20.3             57.1         25.9             9.7               7.1              338.0          664.9      451.1           4.5            48.3                8.5            0.3        3.2           1.2             1.6                      0                       0                     1                     0                            0   \n",
       "...          ...           ...                           ...             ...             ...    ...             ...                   ...           ...           ...         ...         ...                ...                 ...                 ...                  ...         ...               ...             ...                ...                 ...                    ...              ...               ...             ...          ...         ...          ...       ...      ...         ...    ...    ...     ...   ...          ...          ...                 ...             ...         ...            ...              ...                  ...              ...          ...             ...               ...                ...            ...        ...           ...             ...                ...            ...        ...           ...             ...                    ...                     ...                   ...                   ...                          ...   \n",
       "31472 2021-07-03             2  Baptismal Site Qasr al-Yahud               2               0      2               0                     1             0             0           1           0                  0                   1                   0                    1           0                 0               1                  1                   0                      1                0                 0               0            1           0            0         0        0           0  378.5   57.9  720.90   NaN         38.5            1               133.7           378.5        95.0           27.2             30.0                162.8             57.9        109.3            17.7              17.3             1397.4          720.9      356.5          11.4            40.7                9.3            2.9       15.6           2.8             4.4                      1                       1                     1                     0                            1   \n",
       "31473 2021-07-09             2  Baptismal Site Qasr al-Yahud               5               0      5               0                     1             0             0           1           0                  0                   1                   0                    1           0                 0               1                  1                   0                      1                0                 0               0            1           0            0         0        0           0   30.5    7.5    2.60   2.4         38.5            1               121.6           117.9       102.0           29.9             25.6                138.0             47.5        109.6            17.2              11.9              111.7           49.1       60.3           1.5            15.6                8.7            2.9        8.5           2.0             3.7                      0                       0                     0                     0                            0   \n",
       "31474 2021-07-10             2  Baptismal Site Qasr al-Yahud               8               0      8               0                     1             0             0           1           0                  0                   1                   0                    1           0                 0               1                  1                   0                      1                0                 0               0            1           0            0         0        0           0   31.8   12.5   26.90   NaN         38.5            1               138.2           431.3       115.1           41.1             40.8                118.9             77.5        110.0            23.8              12.1             1118.4          902.9      415.0           5.7            46.1               13.0            3.6       17.8           1.8             5.9                      0                       0                     0                     0                            1   \n",
       "31475 2021-07-16             2  Baptismal Site Qasr al-Yahud               5               0      5               0                     1             0             0           1           0                  0                   1                   0                    1           0                 0               1                  1                   0                      1                0                 0               0            1           0            0         0        0           0   35.9   18.9    5.90   0.2         38.5            1               174.7           227.3       119.8           45.4             45.3                207.1            108.4        189.4            27.2              19.7              266.8          545.5       81.8           2.1            22.7                5.0            1.5        8.3           2.6             9.5                      0                       0                     0                     0                            1   \n",
       "31476 2021-08-07             2  Baptismal Site Qasr al-Yahud               9               0      9               0                     1             0             0           1           0                  0                   1                   0                    1           0                 0               1                  1                   0                      1                0                 0               0            1           0            0         0        0           0  441.0   76.9  821.80   NaN         38.5            1               143.3           441.0       105.1           30.0             37.7                185.5             76.9        163.1            18.1              13.9             1219.5          821.8      183.4           5.4            29.7                3.4            2.9       13.2           2.7             7.8                      1                       1                     1                     0                            1   \n",
       "\n",
       "       Jerusalem_pm10_exceeded  Haifa_pm10_exceeded  Ashkelon_pm10_exceeded  Beer-Sheva_pm10_exceeded  Tel_Aviv-Yafo_pm2.5_exceeded  Jerusalem_pm2.5_exceeded  Haifa_pm2.5_exceeded  Ashkelon_pm2.5_exceeded  Beer-Sheva_pm2.5_exceeded  Tel_Aviv-Yafo_so2_exceeded  Jerusalem_so2_exceeded  Haifa_so2_exceeded  Ashkelon_so2_exceeded  Beer-Sheva_so2_exceeded  Tel_Aviv-Yafo_nox_exceeded  Jerusalem_nox_exceeded  Haifa_nox_exceeded  Ashkelon_nox_exceeded  Beer-Sheva_nox_exceeded  Green_border  Season_autumn  Season_spring  Season_summer  Season_winter  \n",
       "0                            0                    0                       0                         0                             0                         0                     0                        0                          0                           0                       0                   0                      0                        0                           1                       1                   1                      0                        0             0              0              0              0              1  \n",
       "1                            1                    0                       0                         0                             1                         1                     1                        0                          0                           0                       0                   0                      0                        0                           1                       1                   1                      0                        1             0              0              0              0              1  \n",
       "2                            1                    0                       0                         0                             1                         1                     1                        0                          0                           0                       0                   0                      0                        0                           1                       1                   1                      0                        1             0              0              0              0              1  \n",
       "3                            1                    0                       0                         0                             1                         1                     1                        0                          0                           0                       0                   0                      0                        0                           1                       1                   1                      0                        1             0              0              0              0              1  \n",
       "4                            0                    0                       0                         0                             0                         1                     0                        0                          0                           0                       0                   0                      0                        0                           1                       1                   1                      0                        1             0              0              0              0              1  \n",
       "...                        ...                  ...                     ...                       ...                           ...                       ...                   ...                      ...                        ...                         ...                     ...                 ...                    ...                      ...                         ...                     ...                 ...                    ...                      ...           ...            ...            ...            ...            ...  \n",
       "31472                        1                    0                       0                         0                             1                         1                     1                        0                          0                           0                       0                   0                      0                        0                           1                       1                   1                      0                        1             1              0              0              1              0  \n",
       "31473                        0                    0                       0                         0                             1                         1                     1                        0                          0                           0                       0                   0                      0                        0                           1                       1                   1                      0                        0             1              0              0              1              0  \n",
       "31474                        1                    0                       0                         0                             1                         1                     1                        0                          0                           0                       0                   0                      0                        0                           1                       1                   1                      0                        1             1              0              0              1              0  \n",
       "31475                        1                    0                       0                         0                             1                         1                     1                        0                          0                           0                       0                   0                      0                        0                           1                       1                   1                      0                        0             1              0              0              1              0  \n",
       "31476                        1                    0                       0                         0                             1                         1                     1                        0                          0                           0                       0                   0                      0                        0                           1                       1                   1                      0                        1             1              0              0              1              0  \n",
       "\n",
       "[31477 rows x 86 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_unformatted_code = \"df = df.loc[df.is_weekend==1]\\ndf.reset_index(drop=True,inplace=True)\\ndf\";\n                var nbb_formatted_code = \"df = df.loc[df.is_weekend == 1]\\ndf.reset_index(drop=True, inplace=True)\\ndf\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.loc[df.is_weekend==1]\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n",
      "547\n",
      "548\n",
      "544\n",
      "550\n",
      "480\n",
      "546\n",
      "547\n",
      "513\n",
      "550\n",
      "543\n",
      "544\n",
      "544\n",
      "549\n",
      "547\n",
      "550\n",
      "547\n",
      "543\n",
      "530\n",
      "539\n",
      "541\n",
      "550\n",
      "550\n",
      "550\n",
      "531\n",
      "533\n",
      "524\n",
      "530\n",
      "545\n",
      "537\n",
      "533\n",
      "543\n",
      "253\n",
      "538\n",
      "530\n",
      "535\n",
      "531\n",
      "548\n",
      "508\n",
      "478\n",
      "548\n",
      "548\n",
      "547\n",
      "529\n",
      "541\n",
      "508\n",
      "526\n",
      "545\n",
      "502\n",
      "460\n",
      "542\n",
      "541\n",
      "515\n",
      "537\n",
      "504\n",
      "494\n",
      "453\n",
      "533\n",
      "428\n",
      "148\n",
      "387\n",
      "96\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 8;\n                var nbb_unformatted_code = \"df_sites = []\\nsites = df.Site_Name.unique()\\nfor site in sites:\\n    tmp = df[df.Site_Name==site]\\n    tmp.reset_index(drop=True,inplace=True)\\n    df_sites.append(tmp)\\n    print(len(tmp))\";\n                var nbb_formatted_code = \"df_sites = []\\nsites = df.Site_Name.unique()\\nfor site in sites:\\n    tmp = df[df.Site_Name == site]\\n    tmp.reset_index(drop=True, inplace=True)\\n    df_sites.append(tmp)\\n    print(len(tmp))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_sites = []\n",
    "sites = df.Site_Name.unique()\n",
    "for site in sites:\n",
    "    tmp = df[df.Site_Name==site]\n",
    "    tmp.reset_index(drop=True,inplace=True)\n",
    "    df_sites.append(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 9;\n                var nbb_unformatted_code = \"# df.isna().sum()\\n# df=df.dropna()\\n# df.reset_index(inplace=True,drop=True)\\nfor d in df_sites:\\n    d.drop(['pm10','nox','so2','pm2.5',\\\"Site_Name\\\"],axis=1,inplace=True)\\n# len(df[df.isnull().any(axis=1)])/len(df)\";\n                var nbb_formatted_code = \"# df.isna().sum()\\n# df=df.dropna()\\n# df.reset_index(inplace=True,drop=True)\\nfor d in df_sites:\\n    d.drop([\\\"pm10\\\", \\\"nox\\\", \\\"so2\\\", \\\"pm2.5\\\", \\\"Site_Name\\\"], axis=1, inplace=True)\\n# len(df[df.isnull().any(axis=1)])/len(df)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df.isna().sum()\n",
    "# df=df.dropna()\n",
    "# df.reset_index(inplace=True,drop=True)\n",
    "for d in df_sites:\n",
    "    d.drop(['pm10','nox','so2','pm2.5',\"Site_Name\"],axis=1,inplace=True)\n",
    "# len(df[df.isnull().any(axis=1)])/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defiend X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 10;\n                var nbb_unformatted_code = \"X_site = []\\ntargets_site = []\\nfor d in df_sites:\\n    X_site.append(d.drop(['Israelis_Count','Tourists_Count','Total',\\\"Date\\\",\\\"Model_number\\\"],axis=1))\\n    targets_site.append(d[['Israelis_Count','Tourists_Count','Total']])\";\n                var nbb_formatted_code = \"X_site = []\\ntargets_site = []\\nfor d in df_sites:\\n    X_site.append(\\n        d.drop(\\n            [\\\"Israelis_Count\\\", \\\"Tourists_Count\\\", \\\"Total\\\", \\\"Date\\\", \\\"Model_number\\\"],\\n            axis=1,\\n        )\\n    )\\n    targets_site.append(d[[\\\"Israelis_Count\\\", \\\"Tourists_Count\\\", \\\"Total\\\"]])\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_site = []\n",
    "targets_site = []\n",
    "for d in df_sites:\n",
    "    X_site.append(d.drop(['Israelis_Count','Tourists_Count','Total',\"Date\",\"Model_number\"],axis=1))\n",
    "    targets_site.append(d[['Israelis_Count','Tourists_Count','Total']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaleing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 11;\n                var nbb_unformatted_code = \"from sklearn.preprocessing import MinMaxScaler\\nscaled_X_sites=[]\\nscaled_targets_sites=[]\\nfor i in range(len(X_site)):\\n    #scale X\\n    scaler = MinMaxScaler()\\n    scaled_X_sites.append( pd.DataFrame(scaler.fit_transform(X_site[i]), columns=X_site[i].columns))\\n\\n    #scale y\\n    scaled_targets_sites.append( np.log(targets_site[i]+0.01))\";\n                var nbb_formatted_code = \"from sklearn.preprocessing import MinMaxScaler\\n\\nscaled_X_sites = []\\nscaled_targets_sites = []\\nfor i in range(len(X_site)):\\n    # scale X\\n    scaler = MinMaxScaler()\\n    scaled_X_sites.append(\\n        pd.DataFrame(scaler.fit_transform(X_site[i]), columns=X_site[i].columns)\\n    )\\n\\n    # scale y\\n    scaled_targets_sites.append(np.log(targets_site[i] + 0.01))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaled_X_sites=[]\n",
    "scaled_targets_sites=[]\n",
    "for i in range(len(X_site)):\n",
    "    #scale X\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_X_sites.append( pd.DataFrame(scaler.fit_transform(X_site[i]), columns=X_site[i].columns))\n",
    "\n",
    "    #scale y\n",
    "    scaled_targets_sites.append( np.log(targets_site[i]+0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "j=0 #############\n",
    "targets = [scaled_targets_sites[j].Israelis_Count,scaled_targets_sites[j].Total,scaled_targets_sites[j].Tourists_Count] # get target info of this site\n",
    "targets_list_name = ['Israelis_Count','Total','Tourists_Count']\n",
    "idx=0\n",
    "for y in targets:\n",
    "    X=scaled_X_sites[j] # get X info of this site\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=312148513)\n",
    "    train_df_scaled = pd.merge(left=X_train, right=y_train, left_index=True, right_index=True)\n",
    "    test_df_scaled = pd.merge(left=X_test, right=y_test, left_index=True, right_index=True)\n",
    "    # step-1: create a cross-validation scheme\n",
    "    folds = KFold(n_splits = 25, shuffle = True, random_state = 100)\n",
    "    \n",
    "    # step-2: specify range of hyperparameters to tune\n",
    "    hyper_params = [{'n_features_to_select': list(range(0, len(X.columns)))}]\n",
    "    \n",
    "    \n",
    "    # step-3: perform grid search\n",
    "    # 3.1 specify model\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_train, y_train)\n",
    "    rfe = RFE(lm)             \n",
    "    \n",
    "    # 3.2 call GridSearchCV()\n",
    "    model_cv = GridSearchCV(estimator = rfe, \n",
    "                            param_grid = hyper_params, \n",
    "                            scoring= 'r2', \n",
    "                            cv = folds, \n",
    "                            verbose = 1,\n",
    "                            return_train_score=True)      \n",
    "    \n",
    "    # fit the model\n",
    "    model_cv.fit(X_train, y_train)   \n",
    "    #######################################################################################################################\n",
    "    #train\n",
    "    fitted = np.exp(model_cv.predict(X_train))\n",
    "    predicted_train = round(pd.Series(fitted, index=y_train.index, name='Predicted_train_'+targets_list_name[idx]),ndigits=2)\n",
    "    orignal_train=np.exp(train_df_scaled[[targets_list_name[idx]]])\n",
    "    train_df = pd.merge(left=orignal_train, right=predicted_train, left_index=True, right_index=True)\n",
    "    train_df\n",
    "    #test\n",
    "    fitted = np.exp(model_cv.predict(X_test))\n",
    "    predicted_test = round(pd.Series(fitted, index=y_test.index, name='Predicted_test_'+targets_list_name[idx]),ndigits=2)\n",
    "    orignal_test = np.exp(test_df_scaled[[targets_list_name[idx]]])\n",
    "    test_df = pd.merge(left=orignal_test, right=predicted_test, left_index=True, right_index=True)\n",
    "    test_df\n",
    "\n",
    "    MSE_Training = metrics.mean_squared_error(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]])\n",
    "    RMSE_Training = np.sqrt(metrics.mean_squared_error(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]]))\n",
    "    MAE_Training = metrics.mean_absolute_error(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]])\n",
    "    R2_Training=metrics.r2_score(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]])\n",
    "    std_Training = np.std(predicted_train)\n",
    "    # f.write(\"------ TRAIN DATA ------\\n\")\n",
    "    # #f.write(\"Model \"+' mod0' +\" Accuracy: \"+str(ACC_Training)+\"\\n\")\n",
    "    # f.write(\"MSE : \"+str(MSE_Training)+\", RMSE: \"+str(RMSE_Training)+\", MAE : \"+str(MAE_Training)+\"\\n\")\n",
    "    # f.write(\"R2 TRAIN \"+ str(R2_Training)+\"\\n\")\n",
    "   #  correct_rows = test_df.loc[abs(test_df['Predicted_test_'+targets_list_name[idx]]-test_df[targets_list_name[idx]])<=50].any(axis=1).count()\n",
    "    #  ACC_Test = round(correct_rows/len(test_df),3)\n",
    "    MSE_Test = metrics.mean_squared_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\n",
    "    RMSE_Test = np.sqrt(metrics.mean_squared_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]]))\n",
    "    MAE_Test = metrics.mean_absolute_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\n",
    "    R2_Test = metrics.r2_score(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\n",
    "    std_test = np.std(predicted_test)\n",
    "    idx+=1\n",
    "\n",
    "    print('rmse_train', RMSE_Training)\n",
    "    print('rmse_test', RMSE_Test)\n",
    "    print('r2_train', R2_Training)\n",
    "    print('r2_test', R2_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model MLR with Pollutions droped Null rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexander Stream-Bet Yannai\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Apollonia\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Arbel\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Avdat\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Ayun Stream\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Bet Alpha\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Bet Guvrin\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Bet Shean\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Bet Shearim\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Caesarea\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Eilat Coral Beach\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "En Afek\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "En Avdat\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "En Gedi\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "En Prat\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Enot Tsukim\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Gamla\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Good Samaritan Museum\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Hai Ramon\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Hamat Tiberias\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Hay-Bar Yotvata\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Hermon Stream (Banias)\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Herodium Park\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Hula\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Khan Beâ€™erot\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Kokhav HaYarden\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Korazim\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Kursi\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Maayan Harod\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Makhtesh Ramon\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Mamshit\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Meâ€˜arot Stream\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Mount Gerizim\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Qumran Park\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Stalactite Cave\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Tel Arad\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Tel Beer Sheva\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Tel Dan\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Tel Hazor\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Tel Megiddo\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "The Masada\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Tzipori\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Yehiam\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Amud Stream\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Ashkelon National Park\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Baram\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Dor HaBonim Beach\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "HaBsor(Eshkol Park)\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Meshushim Stream\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Palmahim Beach\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Snir Stream\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Taninim Stream\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Castel National site\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "En Hemed\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Yehudiya\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "The Majrase â€“ Betiha\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Horshat Tal\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Nimrod Fortress\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Akhziv\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Prat Stream-En Maboâ€˜a\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Gan HaShlosha\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Baptismal Site Qasr al-Yahud\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n",
      "Fitting 12 folds for each of 76 candidates, totalling 912 fits\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 33;\n                var nbb_unformatted_code = \"Model_type= \\\"MLR\\\"\\nres=pd.read_excel(\\\"../../../res.xlsx\\\")\\n\\n\\nfor j in range(len(scaled_X_sites)):\\n  Descripton = \\\"Without Pollutions Without outliers only weekend for each site \\\" + sites[j]\\n  print(sites[j])\\n  targets = [scaled_targets_sites[j].Israelis_Count,scaled_targets_sites[j].Total,scaled_targets_sites[j].Tourists_Count] # get target info of this site\\n  targets_list_name = ['Israelis_Count','Total','Tourists_Count']\\n  idx=0\\n  for y in targets:\\n\\n      #split the data, train the model and get prediction for the training and for the test  \\n      #######################################################################################################################\\n      X=scaled_X_sites[j] # get X info of this site\\n\\n      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=312148513)\\n      train_df_scaled = pd.merge(left=X_train, right=y_train, left_index=True, right_index=True)\\n      test_df_scaled = pd.merge(left=X_test, right=y_test, left_index=True, right_index=True)\\n\\n      lm = LinearRegression()  # define our model using least square method\\n      # step-1: create a cross-validation scheme\\n      folds = KFold(n_splits = 12, shuffle = True, random_state =316173897 )\\n\\n      # step-2: specify range of hyperparameters to tune\\n      hyper_params = [{'n_features_to_select': list(range(0, len(X.columns)))}]\\n\\n\\n      # step-3: perform grid search\\n      # 3.1 specify model\\n      lm = LinearRegression()\\n      lm.fit(X_train, y_train)\\n      rfe = RFE(lm)             \\n\\n      # 3.2 call GridSearchCV()\\n      model_cv = GridSearchCV(estimator = rfe, \\n                              param_grid = hyper_params, \\n                              scoring= 'r2', \\n                              cv = folds, \\n                              verbose = 1,\\n                              return_train_score=True)      \\n\\n      # fit the model\\n      model_cv.fit(X_train, y_train) \\n\\n      #train\\n      fitted = np.exp(model_cv.predict(X_train))\\n      predicted_train = round(pd.Series(fitted, index=y_train.index, name='Predicted_train_'+targets_list_name[idx]),ndigits=2)\\n      orignal_train=np.exp(train_df_scaled[[targets_list_name[idx]]])\\n      train_df = pd.merge(left=orignal_train, right=predicted_train, left_index=True, right_index=True)\\n      train_df\\n\\n      #test\\n      fitted = np.exp(model_cv.predict(X_test))\\n      predicted_test = round(pd.Series(fitted, index=y_test.index, name='Predicted_test_'+targets_list_name[idx]),ndigits=2)\\n      orignal_test = np.exp(test_df_scaled[[targets_list_name[idx]]])\\n      test_df = pd.merge(left=orignal_test, right=predicted_test, left_index=True, right_index=True)\\n      test_df\\n       #######################################################################################################################\\n\\n\\n\\n\\n\\n       #plot the residuals graph\\n       #######################################################################################################################\\n\\n       #calculate the residuals\\n      test_df['residuals'] = test_df['Predicted_test_'+targets_list_name[idx]] - test_df[targets_list_name[idx]]\\n      train_df['residuals'] = train_df['Predicted_train_'+targets_list_name[idx]] - train_df[targets_list_name[idx]]\\n\\n      fig= go.Figure()\\n      fig.add_trace(\\n        go.Scatter(\\n            x=train_df['Predicted_train_'+targets_list_name[idx]],\\n            y=train_df.residuals,\\n            mode='markers',\\n            name='train residuals',\\n            marker_color='blue',\\n            marker_size=1.5,\\n            marker_line_width=0,\\n         )\\n       )\\n      fig.add_trace(\\n        go.Scatter(\\n            x=test_df['Predicted_test_'+targets_list_name[idx]],\\n            y=test_df.residuals,\\n            mode='markers',\\n            name='test residuals',\\n            marker_color='red',\\n            marker_size=1.5,\\n            marker_line_width=0,\\n         )\\n       )\\n      fig.add_trace(\\n         go.Scatter(\\n            x=test_df['Predicted_test_'+targets_list_name[idx]],\\n            y=test_df.residuals*0,\\n            mode='lines',\\n            name='zero line',\\n            marker_color='black',\\n            marker_size=1.5,\\n            marker_line_width=0,\\n         )\\n       )\\n      fig.update_layout(\\n          title=\\\"Residuals of Predicted \\\"+targets_list_name[idx],\\n          xaxis_title=\\\"Predicted \\\"+targets_list_name[idx],\\n          yaxis_title=\\\"Residuals\\\",\\n          font=dict(\\n              size=14,\\n              color=\\\"RebeccaPurple\\\"\\n          )\\n      )\\n      # fig.show()\\n       #######################################################################################################################\\n\\n       #create folder\\n       ########################################\\n      if not os.path.exists(sites[j]):\\n        os.mkdir(sites[j])\\n\\n      if not os.path.exists(sites[j]+'/'+Descripton):\\n        os.mkdir(sites[j]+'/'+Descripton)\\n      fig.write_image(sites[j]+'/'+Descripton+\\\"/results_\\\"+targets_list_name[idx]+'_.png', width=1500, height=600)\\n      #########################################\\n\\n      #create txt file with the metrix result \\n      ################################################################################################################################################     \\n      f = open(sites[j]+'/'+Descripton+\\\"/results_\\\"+targets_list_name[idx]+'_.txt', 'w')\\n\\n      #  correct_rows = train_df.loc[abs(train_df['Predicted_train_'+targets_list_name[idx]]-train_df[targets_list_name[idx]])<=50].any(axis=1).count()\\n      #  ACC_Training = round(correct_rows/len(train_df),3)\\n\\n      if len(test_df.loc[test_df['Predicted_test_'+targets_list_name[idx]]>=np.infty])/len(test_df)*100 <1:\\n          test_df.drop(test_df.loc[test_df['Predicted_test_'+targets_list_name[idx]]>=np.infty].index,inplace=True)\\n      MSE_Training = metrics.mean_squared_error(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]])\\n      RMSE_Training = np.sqrt(metrics.mean_squared_error(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]]))\\n      MAE_Training = metrics.mean_absolute_error(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]])\\n      R2_Training=metrics.r2_score(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]])\\n      std_Training = np.std(predicted_train)\\n\\n      f.write(\\\"------ TRAIN DATA ------\\\\n\\\")\\n      #f.write(\\\"Model \\\"+' mod0' +\\\" Accuracy: \\\"+str(ACC_Training)+\\\"\\\\n\\\")\\n      f.write(\\\"MSE : \\\"+str(MSE_Training)+\\\", RMSE: \\\"+str(RMSE_Training)+\\\", MAE : \\\"+str(MAE_Training)+\\\"\\\\n\\\")\\n      f.write(\\\"R2 TRAIN \\\"+ str(R2_Training)+\\\"\\\\n\\\")\\n\\n\\n      #  correct_rows = test_df.loc[abs(test_df['Predicted_test_'+targets_list_name[idx]]-test_df[targets_list_name[idx]])<=50].any(axis=1).count()\\n      #  ACC_Test = round(correct_rows/len(test_df),3)\\n\\n      MSE_Test = metrics.mean_squared_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\\n      RMSE_Test = np.sqrt(metrics.mean_squared_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]]))\\n      MAE_Test = metrics.mean_absolute_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\\n      R2_Test = metrics.r2_score(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\\n      std_test = np.std(predicted_test)\\n\\n      f.write(\\\"\\\\n\\\")\\n      f.write(\\\"------ TEST DATA ------\\\\n\\\")\\n      #f.write(\\\"Model \\\"+' mod0' +\\\" Accuracy: \\\"+str(ACC_Test)+\\\"\\\\n\\\")\\n      f.write(\\\"MSE : \\\"+str(MSE_Test)+\\\", RMSE: \\\"+str(RMSE_Test)+\\\", MAE : \\\"+str(MAE_Test)+\\\"\\\\n\\\")\\n      f.write(\\\"R2 TEST \\\"+ str(R2_Test)+\\\"\\\\n\\\")\\n      f.write(\\\"--------------------------------\\\\n\\\")\\n\\n      f.close()\\n      ################################################################################################################################################     \\n\\n      #Add to excel result the new line\\n      ################################################################################################################################################\\n      Target=targets_list_name[idx]\\n      Site_in_this_model=sites[j]\\n      new_row = {\\n        'Descripton':Descripton,\\n        \\\"Target\\\":Target,\\n        'Model_type':Model_type,\\n        # 'Model_number':Model_number,\\n        'Site_in_this_model':Site_in_this_model,\\n        \\\"Size Train\\\":len(train_df),\\n        # 'ACC_Training':ACC_Training,\\n        'MAE_Training':MAE_Training,\\n        'MSE_Training':MSE_Training,\\n        'RMSE_Training':RMSE_Training,\\n        'STD_Training':std_Training,\\n        'R2_Training':R2_Training,\\n        \\\"Size Test\\\":len(test_df),\\n        # 'ACC_Test':ACC_Test,\\n        'MAE_Test':MAE_Test,\\n        'MSE_Test':MSE_Test,\\n        'RMSE_Test':RMSE_Test,\\n        'STD_Test':std_test,\\n        'R2_Test':R2_Test \\n        }\\n\\n      res = res.append(new_row,ignore_index=True)\\n      ################################################################################################################################################     \\n\\n      # Index for the next target y\\n      idx+=1\\n\\n\\nres.to_excel(\\\"../../../res.xlsx\\\",index=False)\";\n                var nbb_formatted_code = \"Model_type = \\\"MLR\\\"\\nres = pd.read_excel(\\\"../../../res.xlsx\\\")\\n\\n\\nfor j in range(len(scaled_X_sites)):\\n    Descripton = (\\n        \\\"Without Pollutions Without outliers only weekend for each site \\\" + sites[j]\\n    )\\n    print(sites[j])\\n    targets = [\\n        scaled_targets_sites[j].Israelis_Count,\\n        scaled_targets_sites[j].Total,\\n        scaled_targets_sites[j].Tourists_Count,\\n    ]  # get target info of this site\\n    targets_list_name = [\\\"Israelis_Count\\\", \\\"Total\\\", \\\"Tourists_Count\\\"]\\n    idx = 0\\n    for y in targets:\\n\\n        # split the data, train the model and get prediction for the training and for the test\\n        #######################################################################################################################\\n        X = scaled_X_sites[j]  # get X info of this site\\n\\n        X_train, X_test, y_train, y_test = train_test_split(\\n            X, y, test_size=0.3, random_state=312148513\\n        )\\n        train_df_scaled = pd.merge(\\n            left=X_train, right=y_train, left_index=True, right_index=True\\n        )\\n        test_df_scaled = pd.merge(\\n            left=X_test, right=y_test, left_index=True, right_index=True\\n        )\\n\\n        lm = LinearRegression()  # define our model using least square method\\n        # step-1: create a cross-validation scheme\\n        folds = KFold(n_splits=12, shuffle=True, random_state=316173897)\\n\\n        # step-2: specify range of hyperparameters to tune\\n        hyper_params = [{\\\"n_features_to_select\\\": list(range(0, len(X.columns)))}]\\n\\n        # step-3: perform grid search\\n        # 3.1 specify model\\n        lm = LinearRegression()\\n        lm.fit(X_train, y_train)\\n        rfe = RFE(lm)\\n\\n        # 3.2 call GridSearchCV()\\n        model_cv = GridSearchCV(\\n            estimator=rfe,\\n            param_grid=hyper_params,\\n            scoring=\\\"r2\\\",\\n            cv=folds,\\n            verbose=1,\\n            return_train_score=True,\\n        )\\n\\n        # fit the model\\n        model_cv.fit(X_train, y_train)\\n\\n        # train\\n        fitted = np.exp(model_cv.predict(X_train))\\n        predicted_train = round(\\n            pd.Series(\\n                fitted,\\n                index=y_train.index,\\n                name=\\\"Predicted_train_\\\" + targets_list_name[idx],\\n            ),\\n            ndigits=2,\\n        )\\n        orignal_train = np.exp(train_df_scaled[[targets_list_name[idx]]])\\n        train_df = pd.merge(\\n            left=orignal_train, right=predicted_train, left_index=True, right_index=True\\n        )\\n        train_df\\n\\n        # test\\n        fitted = np.exp(model_cv.predict(X_test))\\n        predicted_test = round(\\n            pd.Series(\\n                fitted,\\n                index=y_test.index,\\n                name=\\\"Predicted_test_\\\" + targets_list_name[idx],\\n            ),\\n            ndigits=2,\\n        )\\n        orignal_test = np.exp(test_df_scaled[[targets_list_name[idx]]])\\n        test_df = pd.merge(\\n            left=orignal_test, right=predicted_test, left_index=True, right_index=True\\n        )\\n        test_df\\n        #######################################################################################################################\\n\\n        # plot the residuals graph\\n        #######################################################################################################################\\n\\n        # calculate the residuals\\n        test_df[\\\"residuals\\\"] = (\\n            test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]]\\n            - test_df[targets_list_name[idx]]\\n        )\\n        train_df[\\\"residuals\\\"] = (\\n            train_df[\\\"Predicted_train_\\\" + targets_list_name[idx]]\\n            - train_df[targets_list_name[idx]]\\n        )\\n\\n        fig = go.Figure()\\n        fig.add_trace(\\n            go.Scatter(\\n                x=train_df[\\\"Predicted_train_\\\" + targets_list_name[idx]],\\n                y=train_df.residuals,\\n                mode=\\\"markers\\\",\\n                name=\\\"train residuals\\\",\\n                marker_color=\\\"blue\\\",\\n                marker_size=1.5,\\n                marker_line_width=0,\\n            )\\n        )\\n        fig.add_trace(\\n            go.Scatter(\\n                x=test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]],\\n                y=test_df.residuals,\\n                mode=\\\"markers\\\",\\n                name=\\\"test residuals\\\",\\n                marker_color=\\\"red\\\",\\n                marker_size=1.5,\\n                marker_line_width=0,\\n            )\\n        )\\n        fig.add_trace(\\n            go.Scatter(\\n                x=test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]],\\n                y=test_df.residuals * 0,\\n                mode=\\\"lines\\\",\\n                name=\\\"zero line\\\",\\n                marker_color=\\\"black\\\",\\n                marker_size=1.5,\\n                marker_line_width=0,\\n            )\\n        )\\n        fig.update_layout(\\n            title=\\\"Residuals of Predicted \\\" + targets_list_name[idx],\\n            xaxis_title=\\\"Predicted \\\" + targets_list_name[idx],\\n            yaxis_title=\\\"Residuals\\\",\\n            font=dict(size=14, color=\\\"RebeccaPurple\\\"),\\n        )\\n        # fig.show()\\n        #######################################################################################################################\\n\\n        # create folder\\n        ########################################\\n        if not os.path.exists(sites[j]):\\n            os.mkdir(sites[j])\\n\\n        if not os.path.exists(sites[j] + \\\"/\\\" + Descripton):\\n            os.mkdir(sites[j] + \\\"/\\\" + Descripton)\\n        fig.write_image(\\n            sites[j]\\n            + \\\"/\\\"\\n            + Descripton\\n            + \\\"/results_\\\"\\n            + targets_list_name[idx]\\n            + \\\"_.png\\\",\\n            width=1500,\\n            height=600,\\n        )\\n        #########################################\\n\\n        # create txt file with the metrix result\\n        ################################################################################################################################################\\n        f = open(\\n            sites[j]\\n            + \\\"/\\\"\\n            + Descripton\\n            + \\\"/results_\\\"\\n            + targets_list_name[idx]\\n            + \\\"_.txt\\\",\\n            \\\"w\\\",\\n        )\\n\\n        #  correct_rows = train_df.loc[abs(train_df['Predicted_train_'+targets_list_name[idx]]-train_df[targets_list_name[idx]])<=50].any(axis=1).count()\\n        #  ACC_Training = round(correct_rows/len(train_df),3)\\n\\n        if (\\n            len(\\n                test_df.loc[\\n                    test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]] >= np.infty\\n                ]\\n            )\\n            / len(test_df)\\n            * 100\\n            < 1\\n        ):\\n            test_df.drop(\\n                test_df.loc[\\n                    test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]] >= np.infty\\n                ].index,\\n                inplace=True,\\n            )\\n        MSE_Training = metrics.mean_squared_error(\\n            train_df[targets_list_name[idx]],\\n            train_df[\\\"Predicted_train_\\\" + targets_list_name[idx]],\\n        )\\n        RMSE_Training = np.sqrt(\\n            metrics.mean_squared_error(\\n                train_df[targets_list_name[idx]],\\n                train_df[\\\"Predicted_train_\\\" + targets_list_name[idx]],\\n            )\\n        )\\n        MAE_Training = metrics.mean_absolute_error(\\n            train_df[targets_list_name[idx]],\\n            train_df[\\\"Predicted_train_\\\" + targets_list_name[idx]],\\n        )\\n        R2_Training = metrics.r2_score(\\n            train_df[targets_list_name[idx]],\\n            train_df[\\\"Predicted_train_\\\" + targets_list_name[idx]],\\n        )\\n        std_Training = np.std(predicted_train)\\n\\n        f.write(\\\"------ TRAIN DATA ------\\\\n\\\")\\n        # f.write(\\\"Model \\\"+' mod0' +\\\" Accuracy: \\\"+str(ACC_Training)+\\\"\\\\n\\\")\\n        f.write(\\n            \\\"MSE : \\\"\\n            + str(MSE_Training)\\n            + \\\", RMSE: \\\"\\n            + str(RMSE_Training)\\n            + \\\", MAE : \\\"\\n            + str(MAE_Training)\\n            + \\\"\\\\n\\\"\\n        )\\n        f.write(\\\"R2 TRAIN \\\" + str(R2_Training) + \\\"\\\\n\\\")\\n\\n        #  correct_rows = test_df.loc[abs(test_df['Predicted_test_'+targets_list_name[idx]]-test_df[targets_list_name[idx]])<=50].any(axis=1).count()\\n        #  ACC_Test = round(correct_rows/len(test_df),3)\\n\\n        MSE_Test = metrics.mean_squared_error(\\n            test_df[targets_list_name[idx]],\\n            test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]],\\n        )\\n        RMSE_Test = np.sqrt(\\n            metrics.mean_squared_error(\\n                test_df[targets_list_name[idx]],\\n                test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]],\\n            )\\n        )\\n        MAE_Test = metrics.mean_absolute_error(\\n            test_df[targets_list_name[idx]],\\n            test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]],\\n        )\\n        R2_Test = metrics.r2_score(\\n            test_df[targets_list_name[idx]],\\n            test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]],\\n        )\\n        std_test = np.std(predicted_test)\\n\\n        f.write(\\\"\\\\n\\\")\\n        f.write(\\\"------ TEST DATA ------\\\\n\\\")\\n        # f.write(\\\"Model \\\"+' mod0' +\\\" Accuracy: \\\"+str(ACC_Test)+\\\"\\\\n\\\")\\n        f.write(\\n            \\\"MSE : \\\"\\n            + str(MSE_Test)\\n            + \\\", RMSE: \\\"\\n            + str(RMSE_Test)\\n            + \\\", MAE : \\\"\\n            + str(MAE_Test)\\n            + \\\"\\\\n\\\"\\n        )\\n        f.write(\\\"R2 TEST \\\" + str(R2_Test) + \\\"\\\\n\\\")\\n        f.write(\\\"--------------------------------\\\\n\\\")\\n\\n        f.close()\\n        ################################################################################################################################################\\n\\n        # Add to excel result the new line\\n        ################################################################################################################################################\\n        Target = targets_list_name[idx]\\n        Site_in_this_model = sites[j]\\n        new_row = {\\n            \\\"Descripton\\\": Descripton,\\n            \\\"Target\\\": Target,\\n            \\\"Model_type\\\": Model_type,\\n            # 'Model_number':Model_number,\\n            \\\"Site_in_this_model\\\": Site_in_this_model,\\n            \\\"Size Train\\\": len(train_df),\\n            # 'ACC_Training':ACC_Training,\\n            \\\"MAE_Training\\\": MAE_Training,\\n            \\\"MSE_Training\\\": MSE_Training,\\n            \\\"RMSE_Training\\\": RMSE_Training,\\n            \\\"STD_Training\\\": std_Training,\\n            \\\"R2_Training\\\": R2_Training,\\n            \\\"Size Test\\\": len(test_df),\\n            # 'ACC_Test':ACC_Test,\\n            \\\"MAE_Test\\\": MAE_Test,\\n            \\\"MSE_Test\\\": MSE_Test,\\n            \\\"RMSE_Test\\\": RMSE_Test,\\n            \\\"STD_Test\\\": std_test,\\n            \\\"R2_Test\\\": R2_Test,\\n        }\\n\\n        res = res.append(new_row, ignore_index=True)\\n        ################################################################################################################################################\\n\\n        # Index for the next target y\\n        idx += 1\\n\\n\\nres.to_excel(\\\"../../../res.xlsx\\\", index=False)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Model_type= \"MLR\"\n",
    "res=pd.read_excel(\"../../../res.xlsx\")\n",
    "\n",
    "\n",
    "for j in range(len(scaled_X_sites)):\n",
    "  Descripton = \"Without Pollutions Without outliers only weekend for each site \" + sites[j]\n",
    "  print(sites[j])\n",
    "  targets = [scaled_targets_sites[j].Israelis_Count,scaled_targets_sites[j].Total,scaled_targets_sites[j].Tourists_Count] # get target info of this site\n",
    "  targets_list_name = ['Israelis_Count','Total','Tourists_Count']\n",
    "  idx=0\n",
    "  for y in targets:\n",
    "\n",
    "      #split the data, train the model and get prediction for the training and for the test  \n",
    "      #######################################################################################################################\n",
    "      X=scaled_X_sites[j] # get X info of this site\n",
    "\n",
    "      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=312148513)\n",
    "      train_df_scaled = pd.merge(left=X_train, right=y_train, left_index=True, right_index=True)\n",
    "      test_df_scaled = pd.merge(left=X_test, right=y_test, left_index=True, right_index=True)\n",
    "\n",
    "      lm = LinearRegression()  # define our model using least square method\n",
    "      # step-1: create a cross-validation scheme\n",
    "      folds = KFold(n_splits = 12, shuffle = True, random_state =316173897 )\n",
    "\n",
    "      # step-2: specify range of hyperparameters to tune\n",
    "      hyper_params = [{'n_features_to_select': list(range(0, len(X.columns)))}]\n",
    "\n",
    "\n",
    "      # step-3: perform grid search\n",
    "      # 3.1 specify model\n",
    "      lm = LinearRegression()\n",
    "      lm.fit(X_train, y_train)\n",
    "      rfe = RFE(lm)             \n",
    "\n",
    "      # 3.2 call GridSearchCV()\n",
    "      model_cv = GridSearchCV(estimator = rfe, \n",
    "                              param_grid = hyper_params, \n",
    "                              scoring= 'r2', \n",
    "                              cv = folds, \n",
    "                              verbose = 1,\n",
    "                              return_train_score=True)      \n",
    "\n",
    "      # fit the model\n",
    "      model_cv.fit(X_train, y_train) \n",
    "\n",
    "      #train\n",
    "      fitted = np.exp(model_cv.predict(X_train))\n",
    "      predicted_train = round(pd.Series(fitted, index=y_train.index, name='Predicted_train_'+targets_list_name[idx]),ndigits=2)\n",
    "      orignal_train=np.exp(train_df_scaled[[targets_list_name[idx]]])\n",
    "      train_df = pd.merge(left=orignal_train, right=predicted_train, left_index=True, right_index=True)\n",
    "      train_df\n",
    "\n",
    "      #test\n",
    "      fitted = np.exp(model_cv.predict(X_test))\n",
    "      predicted_test = round(pd.Series(fitted, index=y_test.index, name='Predicted_test_'+targets_list_name[idx]),ndigits=2)\n",
    "      orignal_test = np.exp(test_df_scaled[[targets_list_name[idx]]])\n",
    "      test_df = pd.merge(left=orignal_test, right=predicted_test, left_index=True, right_index=True)\n",
    "      test_df\n",
    "       #######################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "       #plot the residuals graph\n",
    "       #######################################################################################################################\n",
    "\n",
    "       #calculate the residuals\n",
    "      test_df['residuals'] = test_df['Predicted_test_'+targets_list_name[idx]] - test_df[targets_list_name[idx]]\n",
    "      train_df['residuals'] = train_df['Predicted_train_'+targets_list_name[idx]] - train_df[targets_list_name[idx]]\n",
    "\n",
    "      fig= go.Figure()\n",
    "      fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=train_df['Predicted_train_'+targets_list_name[idx]],\n",
    "            y=train_df.residuals,\n",
    "            mode='markers',\n",
    "            name='train residuals',\n",
    "            marker_color='blue',\n",
    "            marker_size=1.5,\n",
    "            marker_line_width=0,\n",
    "         )\n",
    "       )\n",
    "      fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=test_df['Predicted_test_'+targets_list_name[idx]],\n",
    "            y=test_df.residuals,\n",
    "            mode='markers',\n",
    "            name='test residuals',\n",
    "            marker_color='red',\n",
    "            marker_size=1.5,\n",
    "            marker_line_width=0,\n",
    "         )\n",
    "       )\n",
    "      fig.add_trace(\n",
    "         go.Scatter(\n",
    "            x=test_df['Predicted_test_'+targets_list_name[idx]],\n",
    "            y=test_df.residuals*0,\n",
    "            mode='lines',\n",
    "            name='zero line',\n",
    "            marker_color='black',\n",
    "            marker_size=1.5,\n",
    "            marker_line_width=0,\n",
    "         )\n",
    "       )\n",
    "      fig.update_layout(\n",
    "          title=\"Residuals of Predicted \"+targets_list_name[idx],\n",
    "          xaxis_title=\"Predicted \"+targets_list_name[idx],\n",
    "          yaxis_title=\"Residuals\",\n",
    "          font=dict(\n",
    "              size=14,\n",
    "              color=\"RebeccaPurple\"\n",
    "          )\n",
    "      )\n",
    "      # fig.show()\n",
    "       #######################################################################################################################\n",
    "\n",
    "       #create folder\n",
    "       ########################################\n",
    "      if not os.path.exists(sites[j]):\n",
    "        os.mkdir(sites[j])\n",
    "\n",
    "      if not os.path.exists(sites[j]+'/'+Descripton):\n",
    "        os.mkdir(sites[j]+'/'+Descripton)\n",
    "      fig.write_image(sites[j]+'/'+Descripton+\"/results_\"+targets_list_name[idx]+'_.png', width=1500, height=600)\n",
    "      #########################################\n",
    "\n",
    "      #create txt file with the metrix result \n",
    "      ################################################################################################################################################     \n",
    "      f = open(sites[j]+'/'+Descripton+\"/results_\"+targets_list_name[idx]+'_.txt', 'w')\n",
    "\n",
    "      #  correct_rows = train_df.loc[abs(train_df['Predicted_train_'+targets_list_name[idx]]-train_df[targets_list_name[idx]])<=50].any(axis=1).count()\n",
    "      #  ACC_Training = round(correct_rows/len(train_df),3)\n",
    "\n",
    "      if len(test_df.loc[test_df['Predicted_test_'+targets_list_name[idx]]>=np.infty])/len(test_df)*100 <1:\n",
    "          test_df.drop(test_df.loc[test_df['Predicted_test_'+targets_list_name[idx]]>=np.infty].index,inplace=True)\n",
    "      MSE_Training = metrics.mean_squared_error(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]])\n",
    "      RMSE_Training = np.sqrt(metrics.mean_squared_error(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]]))\n",
    "      MAE_Training = metrics.mean_absolute_error(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]])\n",
    "      R2_Training=metrics.r2_score(train_df[targets_list_name[idx]], train_df['Predicted_train_'+targets_list_name[idx]])\n",
    "      std_Training = np.std(predicted_train)\n",
    "\n",
    "      f.write(\"------ TRAIN DATA ------\\n\")\n",
    "      #f.write(\"Model \"+' mod0' +\" Accuracy: \"+str(ACC_Training)+\"\\n\")\n",
    "      f.write(\"MSE : \"+str(MSE_Training)+\", RMSE: \"+str(RMSE_Training)+\", MAE : \"+str(MAE_Training)+\"\\n\")\n",
    "      f.write(\"R2 TRAIN \"+ str(R2_Training)+\"\\n\")\n",
    "\n",
    "\n",
    "      #  correct_rows = test_df.loc[abs(test_df['Predicted_test_'+targets_list_name[idx]]-test_df[targets_list_name[idx]])<=50].any(axis=1).count()\n",
    "      #  ACC_Test = round(correct_rows/len(test_df),3)\n",
    "\n",
    "      MSE_Test = metrics.mean_squared_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\n",
    "      RMSE_Test = np.sqrt(metrics.mean_squared_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]]))\n",
    "      MAE_Test = metrics.mean_absolute_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\n",
    "      R2_Test = metrics.r2_score(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\n",
    "      std_test = np.std(predicted_test)\n",
    "\n",
    "      f.write(\"\\n\")\n",
    "      f.write(\"------ TEST DATA ------\\n\")\n",
    "      #f.write(\"Model \"+' mod0' +\" Accuracy: \"+str(ACC_Test)+\"\\n\")\n",
    "      f.write(\"MSE : \"+str(MSE_Test)+\", RMSE: \"+str(RMSE_Test)+\", MAE : \"+str(MAE_Test)+\"\\n\")\n",
    "      f.write(\"R2 TEST \"+ str(R2_Test)+\"\\n\")\n",
    "      f.write(\"--------------------------------\\n\")\n",
    "\n",
    "      f.close()\n",
    "      ################################################################################################################################################     \n",
    "\n",
    "      #Add to excel result the new line\n",
    "      ################################################################################################################################################\n",
    "      Target=targets_list_name[idx]\n",
    "      Site_in_this_model=sites[j]\n",
    "      new_row = {\n",
    "        'Descripton':Descripton,\n",
    "        \"Target\":Target,\n",
    "        'Model_type':Model_type,\n",
    "        # 'Model_number':Model_number,\n",
    "        'Site_in_this_model':Site_in_this_model,\n",
    "        \"Size Train\":len(train_df),\n",
    "        # 'ACC_Training':ACC_Training,\n",
    "        'MAE_Training':MAE_Training,\n",
    "        'MSE_Training':MSE_Training,\n",
    "        'RMSE_Training':RMSE_Training,\n",
    "        'STD_Training':std_Training,\n",
    "        'R2_Training':R2_Training,\n",
    "        \"Size Test\":len(test_df),\n",
    "        # 'ACC_Test':ACC_Test,\n",
    "        'MAE_Test':MAE_Test,\n",
    "        'MSE_Test':MSE_Test,\n",
    "        'RMSE_Test':RMSE_Test,\n",
    "        'STD_Test':std_test,\n",
    "        'R2_Test':R2_Test \n",
    "        }\n",
    "\n",
    "      res = res.append(new_row,ignore_index=True)\n",
    "      ################################################################################################################################################     \n",
    "\n",
    "      # Index for the next target y\n",
    "      idx+=1\n",
    "\n",
    "\n",
    "res.to_excel(\"../../../res.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 64;\n                var nbb_unformatted_code = \"# MSE_Test = metrics.mean_squared_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\\nimport math\\n\\nif len(test_df.loc[test_df['Predicted_test_'+targets_list_name[idx]]>=np.infty])/len(test_df)*100 <1:\\n          test_df.drop(test_df.loc[test_df['Predicted_test_'+targets_list_name[idx]]>=np.infty].index)\";\n                var nbb_formatted_code = \"# MSE_Test = metrics.mean_squared_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\\nimport math\\n\\nif (\\n    len(test_df.loc[test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]] >= np.infty])\\n    / len(test_df)\\n    * 100\\n    < 1\\n):\\n    test_df.drop(\\n        test_df.loc[\\n            test_df[\\\"Predicted_test_\\\" + targets_list_name[idx]] >= np.infty\\n        ].index\\n    )\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MSE_Test = metrics.mean_squared_error(test_df[targets_list_name[idx]], test_df['Predicted_test_'+targets_list_name[idx]])\n",
    "\n",
    "if len(test_df.loc[test_df['Predicted_test_'+targets_list_name[idx]]>=np.infty])/len(test_df)*100 <1:\n",
    "          test_df.drop(test_df.loc[test_df['Predicted_test_'+targets_list_name[idx]]>=np.infty].index)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ace568d36d830c5571f2829ec101ed577db7d1f44057a629faa8733711eb527"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
